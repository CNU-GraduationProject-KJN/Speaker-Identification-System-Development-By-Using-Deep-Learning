{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res50_model = ResNet50(weights='imagenet')\n",
    "res50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=res50_model.input, outputs=res50_model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kwakjuheon', 'kimjiho', 'songyejin', 'parksohui', 'moonyeonwoo', 'kangsubin', 'leekyeongeun', 'chochaeyeon', 'shindonghwan', 'kwakmirae', 'kimhyeryeong', 'chaeminjoon', 'kwakyiheon', 'leesumin', 'choihayoung', 'kangyeseo', 'kwakmihyang', 'eundano', 'limjinju', 'kimseongje', 'kwakbokyeong', 'ahnhyojin', 'heosehun', 'choijiwon', 'ahnjeongsuk', 'parkyeongseon', 'kwaksangpil', 'kodohyeon', 'kwonyuna', 'kwoneunkyung', 'johaesu', 'leebyeongjin', 'hyeonsanghyeok', 'jennie', 'simseungmin', 'parksomi', 'yuminji', 'parksojin', 'kwonyeonwoo', 'ladakyeong', 'janghyomin', 'parkeunbi', 'parkdayeung', 'parkjongae', 'hansohee', 'janggyeoul', 'leewooju', 'nomyungok', 'heoyoonjung', 'heojaemin', 'kimsoyung', 'chuminha', 'kimhyeonsu', 'chaesonghwa', 'kwonyulim', 'kimminyoung', 'jueunhong', 'leejeongju', 'kwonnahui', 'kimdayeong', 'kwonsundo', 'kimhyeona', 'leehyojin', 'yuminji', 'jeonghojun', 'kanghyeyun', 'ohjiwon', 'kimsubin', 'kimkihyeon', 'kimminji', 'myeongjaewon', 'kimjihyeon', 'choisuyeon', 'hwanghyebin', 'jangsoojin', 'kimhongjoo', 'kimhyorin', 'kimjihyun', 'kimsongyi', 'kotaewan', 'leedanbee', 'leejungjoon', 'parkjongkook', 'sungsoohyun', 'wonjoonho', 'wonsonghee', 'yoonhyeeun', 'kimjuyeong', 'kimjaein', 'yoohaekyung', 'hanyukyung', 'yoojungkyun', 'parkjongsang', 'leesol', 'kimsunghan', 'kimminji', 'hanseungoh', 'ahnjiwoo']\n"
     ]
    }
   ],
   "source": [
    "class_names = os.listdir(\"../../feature/feature_logscale_stft/\")\n",
    "class_names.sort()\n",
    "   \n",
    "forPrintList = [class_name.split('_')[1] for class_name in class_names]\n",
    "print(forPrintList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017019740001\n",
      "2017019740001_kwakjuheon_4.npy 0\n",
      "2017019740001_kwakjuheon_1.npy 1\n",
      "2017019740001_kwakjuheon_0.npy 2\n",
      "2017019740001_kwakjuheon_2.npy 3\n",
      "2017019740001_kwakjuheon_3.npy 4\n",
      "2017019740002\n",
      "2017019740002_kimjiho_3.npy 0\n",
      "2017019740002_kimjiho_1.npy 1\n",
      "2017019740002_kimjiho_2.npy 2\n",
      "2017019740002_kimjiho_4.npy 3\n",
      "2017019740002_kimjiho_0.npy 4\n",
      "2017019740003\n",
      "2017019740003_songyejin_2.npy 0\n",
      "2017019740003_songyejin_3.npy 1\n",
      "2017019740003_songyejin_4.npy 2\n",
      "2017019740003_songyejin_1.npy 3\n",
      "2017019740003_songyejin_0.npy 4\n",
      "2017019740004\n",
      "2017019740004_parksohui_2.npy 0\n",
      "2017019740004_parksohui_1.npy 1\n",
      "2017019740004_parksohui_3.npy 2\n",
      "2017019740004_parksohui_0.npy 3\n",
      "2017019740004_parksohui_4.npy 4\n",
      "2017019740005\n",
      "2017019740005_moonyeonwoo_3.npy 0\n",
      "2017019740005_moonyeonwoo_2.npy 1\n",
      "2017019740005_moonyeonwoo_0.npy 2\n",
      "2017019740005_moonyeonwoo_4.npy 3\n",
      "2017019740005_moonyeonwoo_1.npy 4\n",
      "2017019740006\n",
      "2017019740006_kangsubin_3.npy 0\n",
      "2017019740006_kangsubin_1.npy 1\n",
      "2017019740006_kangsubin_4.npy 2\n",
      "2017019740006_kangsubin_2.npy 3\n",
      "2017019740006_kangsubin_0.npy 4\n",
      "2017019740007\n",
      "2017019740007_leekyeongeun_2.npy 0\n",
      "2017019740007_leekyeongeun_4.npy 1\n",
      "2017019740007_leekyeongeun_0.npy 2\n",
      "2017019740007_leekyeongeun_3.npy 3\n",
      "2017019740007_leekyeongeun_1.npy 4\n",
      "2017019740008\n",
      "2017019740008_chochaeyeon_4.npy 0\n",
      "2017019740008_chochaeyeon_3.npy 1\n",
      "2017019740008_chochaeyeon_2.npy 2\n",
      "2017019740008_chochaeyeon_1.npy 3\n",
      "2017019740008_chochaeyeon_0.npy 4\n",
      "2017019740009\n",
      "2017019740009_shindonghwan_1.npy 0\n",
      "2017019740009_shindonghwan_2.npy 1\n",
      "2017019740009_shindonghwan_4.npy 2\n",
      "2017019740009_shindonghwan_0.npy 3\n",
      "2017019740009_shindonghwan_3.npy 4\n",
      "2017019740010\n",
      "2017019740010_kwakmirae_4.npy 0\n",
      "2017019740010_kwakmirae_0.npy 1\n",
      "2017019740010_kwakmirae_1.npy 2\n",
      "2017019740010_kwakmirae_2.npy 3\n",
      "2017019740010_kwakmirae_3.npy 4\n",
      "2017019740011\n",
      "2017019740011_kimhyeryeong_1.npy 0\n",
      "2017019740011_kimhyeryeong_3.npy 1\n",
      "2017019740011_kimhyeryeong_0.npy 2\n",
      "2017019740011_kimhyeryeong_4.npy 3\n",
      "2017019740011_kimhyeryeong_2.npy 4\n",
      "2017019740012\n",
      "2017019740012_chaeminjoon_0.npy 0\n",
      "2017019740012_chaeminjoon_4.npy 1\n",
      "2017019740012_chaeminjoon_1.npy 2\n",
      "2017019740012_chaeminjoon_2.npy 3\n",
      "2017019740012_chaeminjoon_3.npy 4\n",
      "2017019740013\n",
      "2017019740013_kwakyiheon_0.npy 0\n",
      "2017019740013_kwakyiheon_1.npy 1\n",
      "2017019740013_kwakyiheon_4.npy 2\n",
      "2017019740013_kwakyiheon_2.npy 3\n",
      "2017019740013_kwakyiheon_3.npy 4\n",
      "2017019740014\n",
      "2017019740014_leesumin_0.npy 0\n",
      "2017019740014_leesumin_4.npy 1\n",
      "2017019740014_leesumin_2.npy 2\n",
      "2017019740014_leesumin_1.npy 3\n",
      "2017019740014_leesumin_3.npy 4\n",
      "2017019740015\n",
      "2017019740015_choihayoung_3.npy 0\n",
      "2017019740015_choihayoung_1.npy 1\n",
      "2017019740015_choihayoung_4.npy 2\n",
      "2017019740015_choihayoung_2.npy 3\n",
      "2017019740015_choihayoung_0.npy 4\n",
      "2017019740016\n",
      "2017019740016_kangyeseo_0.npy 0\n",
      "2017019740016_kangyeseo_3.npy 1\n",
      "2017019740016_kangyeseo_2.npy 2\n",
      "2017019740016_kangyeseo_4.npy 3\n",
      "2017019740016_kangyeseo_1.npy 4\n",
      "2017019740017\n",
      "2017019740017_kwakmihyang_3.npy 0\n",
      "2017019740017_kwakmihyang_2.npy 1\n",
      "2017019740017_kwakmihyang_1.npy 2\n",
      "2017019740017_kwakmihyang_4.npy 3\n",
      "2017019740017_kwakmihyang_0.npy 4\n",
      "2017019740018\n",
      "2017019740018_eundano_0.npy 0\n",
      "2017019740018_eundano_4.npy 1\n",
      "2017019740018_eundano_1.npy 2\n",
      "2017019740018_eundano_3.npy 3\n",
      "2017019740018_eundano_2.npy 4\n",
      "2017019740019\n",
      "2017019740019_limjinju_1.npy 0\n",
      "2017019740019_limjinju_3.npy 1\n",
      "2017019740019_limjinju_4.npy 2\n",
      "2017019740019_limjinju_2.npy 3\n",
      "2017019740019_limjinju_0.npy 4\n",
      "2017019740020\n",
      "2017019740020_kimseongje_3.npy 0\n",
      "2017019740020_kimseongje_1.npy 1\n",
      "2017019740020_kimseongje_4.npy 2\n",
      "2017019740020_kimseongje_2.npy 3\n",
      "2017019740020_kimseongje_0.npy 4\n",
      "2017019740021\n",
      "2017019740021_kwakbokyeong_3.npy 0\n",
      "2017019740021_kwakbokyeong_2.npy 1\n",
      "2017019740021_kwakbokyeong_0.npy 2\n",
      "2017019740021_kwakbokyeong_1.npy 3\n",
      "2017019740021_kwakbokyeong_4.npy 4\n",
      "2017019740022\n",
      "2017019740022_ahnhyojin_0.npy 0\n",
      "2017019740022_ahnhyojin_1.npy 1\n",
      "2017019740022_ahnhyojin_2.npy 2\n",
      "2017019740022_ahnhyojin_3.npy 3\n",
      "2017019740022_ahnhyojin_4.npy 4\n",
      "2017019740023\n",
      "2017019740023_heosehun_3.npy 0\n",
      "2017019740023_heosehun_0.npy 1\n",
      "2017019740023_heosehun_4.npy 2\n",
      "2017019740023_heosehun_2.npy 3\n",
      "2017019740023_heosehun_1.npy 4\n",
      "2017019740024\n",
      "2017019740024_choijiwon_2.npy 0\n",
      "2017019740024_choijiwon_0.npy 1\n",
      "2017019740024_choijiwon_3.npy 2\n",
      "2017019740024_choijiwon_1.npy 3\n",
      "2017019740024_choijiwon_4.npy 4\n",
      "2017019740025\n",
      "2017019740025_ahnjeongsuk_2.npy 0\n",
      "2017019740025_ahnjeongsuk_4.npy 1\n",
      "2017019740025_ahnjeongsuk_1.npy 2\n",
      "2017019740025_ahnjeongsuk_0.npy 3\n",
      "2017019740025_ahnjeongsuk_3.npy 4\n",
      "2017019740026\n",
      "2017019740026_parkyeongseon_1.npy 0\n",
      "2017019740026_parkyeongseon_0.npy 1\n",
      "2017019740026_parkyeongseon_2.npy 2\n",
      "2017019740026_parkyeongseon_4.npy 3\n",
      "2017019740026_parkyeongseon_3.npy 4\n",
      "2017019740027\n",
      "2017019740027_kwaksangpil_1.npy 0\n",
      "2017019740027_kwaksangpil_3.npy 1\n",
      "2017019740027_kwaksangpil_2.npy 2\n",
      "2017019740027_kwaksangpil_0.npy 3\n",
      "2017019740027_kwaksangpil_4.npy 4\n",
      "2017019740028\n",
      "2017019740028_kodohyeon_2.npy 0\n",
      "2017019740028_kodohyeon_4.npy 1\n",
      "2017019740028_kodohyeon_1.npy 2\n",
      "2017019740028_kodohyeon_3.npy 3\n",
      "2017019740028_kodohyeon_0.npy 4\n",
      "2017019770001\n",
      "2017019770001_kwonyuna_1.npy 0\n",
      "2017019770001_kwonyuna_0.npy 1\n",
      "2017019770001_kwonyuna_3.npy 2\n",
      "2017019770001_kwonyuna_2.npy 3\n",
      "2017019770001_kwonyuna_4.npy 4\n",
      "2017019770002\n",
      "2017019770002_kwoneunkyung_3.npy 0\n",
      "2017019770002_kwoneunkyung_2.npy 1\n",
      "2017019770002_kwoneunkyung_0.npy 2\n",
      "2017019770002_kwoneunkyung_1.npy 3\n",
      "2017019770002_kwoneunkyung_4.npy 4\n",
      "2017019770003\n",
      "2017019770003_johaesu_4.npy 0\n",
      "2017019770003_johaesu_0.npy 1\n",
      "2017019770003_johaesu_1.npy 2\n",
      "2017019770003_johaesu_2.npy 3\n",
      "2017019770003_johaesu_3.npy 4\n",
      "2017019770004\n",
      "2017019770004_leebyeongjin_4.npy 0\n",
      "2017019770004_leebyeongjin_3.npy 1\n",
      "2017019770004_leebyeongjin_0.npy 2\n",
      "2017019770004_leebyeongjin_2.npy 3\n",
      "2017019770004_leebyeongjin_1.npy 4\n",
      "2017019770005\n",
      "2017019770005_hyeonsanghyeok_1.npy 0\n",
      "2017019770005_hyeonsanghyeok_2.npy 1\n",
      "2017019770005_hyeonsanghyeok_4.npy 2\n",
      "2017019770005_hyeonsanghyeok_0.npy 3\n",
      "2017019770005_hyeonsanghyeok_3.npy 4\n",
      "2017019770006\n",
      "2017019770006_jennie_4.npy 0\n",
      "2017019770006_jennie_0.npy 1\n",
      "2017019770006_jennie_1.npy 2\n",
      "2017019770006_jennie_2.npy 3\n",
      "2017019770006_jennie_3.npy 4\n",
      "2017019770007\n",
      "2017019770007_simseungmin_3.npy 0\n",
      "2017019770007_simseungmin_2.npy 1\n",
      "2017019770007_simseungmin_1.npy 2\n",
      "2017019770007_simseungmin_4.npy 3\n",
      "2017019770007_simseungmin_0.npy 4\n",
      "2017019770008\n",
      "2017019770008_parksomi_2.npy 0\n",
      "2017019770008_parksomi_1.npy 1\n",
      "2017019770008_parksomi_3.npy 2\n",
      "2017019770008_parksomi_0.npy 3\n",
      "2017019770008_parksomi_4.npy 4\n",
      "2017019770009\n",
      "2017019770009_yuminji_3.npy 0\n",
      "2017019770009_yuminji_4.npy 1\n",
      "2017019770009_yuminji_0.npy 2\n",
      "2017019770009_yuminji_1.npy 3\n",
      "2017019770009_yuminji_2.npy 4\n",
      "2017019770010\n",
      "2017019770010_parksojin_1.npy 0\n",
      "2017019770010_parksojin_4.npy 1\n",
      "2017019770010_parksojin_0.npy 2\n",
      "2017019770010_parksojin_3.npy 3\n",
      "2017019770010_parksojin_2.npy 4\n",
      "2017019770011\n",
      "2017019770011_kwonyeonwoo_0.npy 0\n",
      "2017019770011_kwonyeonwoo_2.npy 1\n",
      "2017019770011_kwonyeonwoo_3.npy 2\n",
      "2017019770011_kwonyeonwoo_4.npy 3\n",
      "2017019770011_kwonyeonwoo_1.npy 4\n",
      "2017019770012\n",
      "2017019770012_ladakyeong_1.npy 0\n",
      "2017019770012_ladakyeong_4.npy 1\n",
      "2017019770012_ladakyeong_3.npy 2\n",
      "2017019770012_ladakyeong_0.npy 3\n",
      "2017019770012_ladakyeong_2.npy 4\n",
      "2017019770013\n",
      "2017019770013_janghyomin_2.npy 0\n",
      "2017019770013_janghyomin_3.npy 1\n",
      "2017019770013_janghyomin_0.npy 2\n",
      "2017019770013_janghyomin_1.npy 3\n",
      "2017019770013_janghyomin_4.npy 4\n",
      "2017019770014\n",
      "2017019770014_parkeunbi_3.npy 0\n",
      "2017019770014_parkeunbi_2.npy 1\n",
      "2017019770014_parkeunbi_0.npy 2\n",
      "2017019770014_parkeunbi_1.npy 3\n",
      "2017019770014_parkeunbi_4.npy 4\n",
      "2017019770015\n",
      "2017019770015_parkdayeung_4.npy 0\n",
      "2017019770015_parkdayeung_2.npy 1\n",
      "2017019770015_parkdayeung_3.npy 2\n",
      "2017019770015_parkdayeung_1.npy 3\n",
      "2017019770015_parkdayeung_0.npy 4\n",
      "2017019770016\n",
      "2017019770016_parkjongae_4.npy 0\n",
      "2017019770016_parkjongae_2.npy 1\n",
      "2017019770016_parkjongae_3.npy 2\n",
      "2017019770016_parkjongae_0.npy 3\n",
      "2017019770016_parkjongae_1.npy 4\n",
      "2017019770017\n",
      "2017019770017_hansohee_3.npy 0\n",
      "2017019770017_hansohee_1.npy 1\n",
      "2017019770017_hansohee_0.npy 2\n",
      "2017019770017_hansohee_2.npy 3\n",
      "2017019770017_hansohee_4.npy 4\n",
      "2017019770018\n",
      "2017019770018_janggyeoul_4.npy 0\n",
      "2017019770018_janggyeoul_3.npy 1\n",
      "2017019770018_janggyeoul_2.npy 2\n",
      "2017019770018_janggyeoul_1.npy 3\n",
      "2017019770018_janggyeoul_0.npy 4\n",
      "2017019770019\n",
      "2017019770019_leewooju_3.npy 0\n",
      "2017019770019_leewooju_4.npy 1\n",
      "2017019770019_leewooju_1.npy 2\n",
      "2017019770019_leewooju_2.npy 3\n",
      "2017019770019_leewooju_0.npy 4\n",
      "2017019770020\n",
      "2017019770020_nomyungok_4.npy 0\n",
      "2017019770020_nomyungok_1.npy 1\n",
      "2017019770020_nomyungok_0.npy 2\n",
      "2017019770020_nomyungok_2.npy 3\n",
      "2017019770020_nomyungok_3.npy 4\n",
      "2017019770021\n",
      "2017019770021_heoyoonjung_4.npy 0\n",
      "2017019770021_heoyoonjung_2.npy 1\n",
      "2017019770021_heoyoonjung_3.npy 2\n",
      "2017019770021_heoyoonjung_1.npy 3\n",
      "2017019770021_heoyoonjung_0.npy 4\n",
      "2017019770022\n",
      "2017019770022_heojaemin_4.npy 0\n",
      "2017019770022_heojaemin_1.npy 1\n",
      "2017019770022_heojaemin_2.npy 2\n",
      "2017019770022_heojaemin_0.npy 3\n",
      "2017019770022_heojaemin_3.npy 4\n",
      "2017019770023\n",
      "2017019770023_kimsoyung_4.npy 0\n",
      "2017019770023_kimsoyung_0.npy 1\n",
      "2017019770023_kimsoyung_1.npy 2\n",
      "2017019770023_kimsoyung_2.npy 3\n",
      "2017019770023_kimsoyung_3.npy 4\n",
      "2017019770024\n",
      "2017019770024_chuminha_0.npy 0\n",
      "2017019770024_chuminha_4.npy 1\n",
      "2017019770024_chuminha_2.npy 2\n",
      "2017019770024_chuminha_3.npy 3\n",
      "2017019770024_chuminha_1.npy 4\n",
      "2017019770025\n",
      "2017019770025_kimhyeonsu_1.npy 0\n",
      "2017019770025_kimhyeonsu_2.npy 1\n",
      "2017019770025_kimhyeonsu_4.npy 2\n",
      "2017019770025_kimhyeonsu_0.npy 3\n",
      "2017019770025_kimhyeonsu_3.npy 4\n",
      "2017019770026\n",
      "2017019770026_chaesonghwa_2.npy 0\n",
      "2017019770026_chaesonghwa_0.npy 1\n",
      "2017019770026_chaesonghwa_1.npy 2\n",
      "2017019770026_chaesonghwa_4.npy 3\n",
      "2017019770026_chaesonghwa_3.npy 4\n",
      "2017019770027\n",
      "2017019770027_kwonyulim_2.npy 0\n",
      "2017019770027_kwonyulim_3.npy 1\n",
      "2017019770027_kwonyulim_4.npy 2\n",
      "2017019770027_kwonyulim_1.npy 3\n",
      "2017019770027_kwonyulim_0.npy 4\n",
      "2017019770028\n",
      "2017019770028_kimminyoung_3.npy 0\n",
      "2017019770028_kimminyoung_2.npy 1\n",
      "2017019770028_kimminyoung_4.npy 2\n",
      "2017019770028_kimminyoung_0.npy 3\n",
      "2017019770028_kimminyoung_1.npy 4\n",
      "2017019770029\n",
      "2017019770029_jueunhong_4.npy 0\n",
      "2017019770029_jueunhong_0.npy 1\n",
      "2017019770029_jueunhong_3.npy 2\n",
      "2017019770029_jueunhong_1.npy 3\n",
      "2017019770029_jueunhong_2.npy 4\n",
      "2017019770030\n",
      "2017019770030_leejeongju_1.npy 0\n",
      "2017019770030_leejeongju_0.npy 1\n",
      "2017019770030_leejeongju_2.npy 2\n",
      "2017019770030_leejeongju_4.npy 3\n",
      "2017019770030_leejeongju_3.npy 4\n",
      "2017019770031\n",
      "2017019770031_kwonnahui_1.npy 0\n",
      "2017019770031_kwonnahui_4.npy 1\n",
      "2017019770031_kwonnahui_3.npy 2\n",
      "2017019770031_kwonnahui_2.npy 3\n",
      "2017019770031_kwonnahui_0.npy 4\n",
      "2017019770032\n",
      "2017019770032_kimdayeong_2.npy 0\n",
      "2017019770032_kimdayeong_0.npy 1\n",
      "2017019770032_kimdayeong_1.npy 2\n",
      "2017019770032_kimdayeong_4.npy 3\n",
      "2017019770032_kimdayeong_3.npy 4\n",
      "2017019770033\n",
      "2017019770033_kwonsundo_3.npy 0\n",
      "2017019770033_kwonsundo_1.npy 1\n",
      "2017019770033_kwonsundo_2.npy 2\n",
      "2017019770033_kwonsundo_4.npy 3\n",
      "2017019770033_kwonsundo_0.npy 4\n",
      "2017019770034\n",
      "2017019770034_kimhyeona_2.npy 0\n",
      "2017019770034_kimhyeona_3.npy 1\n",
      "2017019770034_kimhyeona_1.npy 2\n",
      "2017019770034_kimhyeona_0.npy 3\n",
      "2017019770034_kimhyeona_4.npy 4\n",
      "2017019770035\n",
      "2017019770035_leehyojin_4.npy 0\n",
      "2017019770035_leehyojin_1.npy 1\n",
      "2017019770035_leehyojin_3.npy 2\n",
      "2017019770035_leehyojin_2.npy 3\n",
      "2017019770035_leehyojin_0.npy 4\n",
      "2017019770036\n",
      "2017019770036_yuminji_2.npy 0\n",
      "2017019770036_yuminji_1.npy 1\n",
      "2017019770036_yuminji_3.npy 2\n",
      "2017019770036_yuminji_4.npy 3\n",
      "2017019770036_yuminji_0.npy 4\n",
      "2017019770037\n",
      "2017019770037_jeonghojun_0.npy 0\n",
      "2017019770037_jeonghojun_3.npy 1\n",
      "2017019770037_jeonghojun_1.npy 2\n",
      "2017019770037_jeonghojun_2.npy 3\n",
      "2017019770037_jeonghojun_4.npy 4\n",
      "2017019770038\n",
      "2017019770038_kanghyeyun_1.npy 0\n",
      "2017019770038_kanghyeyun_3.npy 1\n",
      "2017019770038_kanghyeyun_2.npy 2\n",
      "2017019770038_kanghyeyun_0.npy 3\n",
      "2017019770038_kanghyeyun_4.npy 4\n",
      "2017019770039\n",
      "2017019770039_ohjiwon_1.npy 0\n",
      "2017019770039_ohjiwon_4.npy 1\n",
      "2017019770039_ohjiwon_0.npy 2\n",
      "2017019770039_ohjiwon_3.npy 3\n",
      "2017019770039_ohjiwon_2.npy 4\n",
      "2017019880001\n",
      "2017019880001_kimsubin_1.npy 0\n",
      "2017019880001_kimsubin_4.npy 1\n",
      "2017019880001_kimsubin_3.npy 2\n",
      "2017019880001_kimsubin_0.npy 3\n",
      "2017019880001_kimsubin_2.npy 4\n",
      "2017019880002\n",
      "2017019880002_kimkihyeon_0.npy 0\n",
      "2017019880002_kimkihyeon_3.npy 1\n",
      "2017019880002_kimkihyeon_4.npy 2\n",
      "2017019880002_kimkihyeon_2.npy 3\n",
      "2017019880002_kimkihyeon_1.npy 4\n",
      "2017019880003\n",
      "2017019880003_kimminji_1.npy 0\n",
      "2017019880003_kimminji_4.npy 1\n",
      "2017019880003_kimminji_2.npy 2\n",
      "2017019880003_kimminji_0.npy 3\n",
      "2017019880003_kimminji_3.npy 4\n",
      "2017019880004\n",
      "2017019880004_myeongjaewon_2.npy 0\n",
      "2017019880004_myeongjaewon_1.npy 1\n",
      "2017019880004_myeongjaewon_0.npy 2\n",
      "2017019880004_myeongjaewon_4.npy 3\n",
      "2017019880004_myeongjaewon_3.npy 4\n",
      "2017019880005\n",
      "2017019880005_kimjihyeon_1.npy 0\n",
      "2017019880005_kimjihyeon_0.npy 1\n",
      "2017019880005_kimjihyeon_4.npy 2\n",
      "2017019880005_kimjihyeon_3.npy 3\n",
      "2017019880005_kimjihyeon_2.npy 4\n",
      "2017019880006\n",
      "2017019880006_choisuyeon_3.npy 0\n",
      "2017019880006_choisuyeon_4.npy 1\n",
      "2017019880006_choisuyeon_1.npy 2\n",
      "2017019880006_choisuyeon_2.npy 3\n",
      "2017019880006_choisuyeon_0.npy 4\n",
      "2017019880007\n",
      "2017019880007_hwanghyebin_4.npy 0\n",
      "2017019880007_hwanghyebin_2.npy 1\n",
      "2017019880007_hwanghyebin_1.npy 2\n",
      "2017019880007_hwanghyebin_3.npy 3\n",
      "2017019880007_hwanghyebin_0.npy 4\n",
      "2017019880008\n",
      "2017019880008_jangsoojin_3.npy 0\n",
      "2017019880008_jangsoojin_0.npy 1\n",
      "2017019880008_jangsoojin_1.npy 2\n",
      "2017019880008_jangsoojin_2.npy 3\n",
      "2017019880008_jangsoojin_4.npy 4\n",
      "2017019880009\n",
      "2017019880009_kimhongjoo_3.npy 0\n",
      "2017019880009_kimhongjoo_0.npy 1\n",
      "2017019880009_kimhongjoo_1.npy 2\n",
      "2017019880009_kimhongjoo_4.npy 3\n",
      "2017019880009_kimhongjoo_2.npy 4\n",
      "2017019880010\n",
      "2017019880010_kimhyorin_0.npy 0\n",
      "2017019880010_kimhyorin_1.npy 1\n",
      "2017019880010_kimhyorin_4.npy 2\n",
      "2017019880010_kimhyorin_3.npy 3\n",
      "2017019880010_kimhyorin_2.npy 4\n",
      "2017019880011\n",
      "2017019880011_kimjihyun_1.npy 0\n",
      "2017019880011_kimjihyun_3.npy 1\n",
      "2017019880011_kimjihyun_2.npy 2\n",
      "2017019880011_kimjihyun_0.npy 3\n",
      "2017019880011_kimjihyun_4.npy 4\n",
      "2017019880012\n",
      "2017019880012_kimsongyi_4.npy 0\n",
      "2017019880012_kimsongyi_1.npy 1\n",
      "2017019880012_kimsongyi_3.npy 2\n",
      "2017019880012_kimsongyi_2.npy 3\n",
      "2017019880012_kimsongyi_0.npy 4\n",
      "2017019880013\n",
      "2017019880013_kotaewan_0.npy 0\n",
      "2017019880013_kotaewan_1.npy 1\n",
      "2017019880013_kotaewan_3.npy 2\n",
      "2017019880013_kotaewan_2.npy 3\n",
      "2017019880013_kotaewan_4.npy 4\n",
      "2017019880014\n",
      "2017019880014_leedanbee_1.npy 0\n",
      "2017019880014_leedanbee_2.npy 1\n",
      "2017019880014_leedanbee_4.npy 2\n",
      "2017019880014_leedanbee_0.npy 3\n",
      "2017019880014_leedanbee_3.npy 4\n",
      "2017019880015\n",
      "2017019880015_leejungjoon_3.npy 0\n",
      "2017019880015_leejungjoon_2.npy 1\n",
      "2017019880015_leejungjoon_4.npy 2\n",
      "2017019880015_leejungjoon_1.npy 3\n",
      "2017019880015_leejungjoon_0.npy 4\n",
      "2017019880016\n",
      "2017019880016_parkjongkook_0.npy 0\n",
      "2017019880016_parkjongkook_3.npy 1\n",
      "2017019880016_parkjongkook_4.npy 2\n",
      "2017019880016_parkjongkook_1.npy 3\n",
      "2017019880016_parkjongkook_2.npy 4\n",
      "2017019880017\n",
      "2017019880017_sungsoohyun_0.npy 0\n",
      "2017019880017_sungsoohyun_1.npy 1\n",
      "2017019880017_sungsoohyun_3.npy 2\n",
      "2017019880017_sungsoohyun_4.npy 3\n",
      "2017019880017_sungsoohyun_2.npy 4\n",
      "2017019880018\n",
      "2017019880018_wonjoonho_4.npy 0\n",
      "2017019880018_wonjoonho_0.npy 1\n",
      "2017019880018_wonjoonho_3.npy 2\n",
      "2017019880018_wonjoonho_1.npy 3\n",
      "2017019880018_wonjoonho_2.npy 4\n",
      "2017019880019\n",
      "2017019880019_wonsonghee_2.npy 0\n",
      "2017019880019_wonsonghee_3.npy 1\n",
      "2017019880019_wonsonghee_4.npy 2\n",
      "2017019880019_wonsonghee_1.npy 3\n",
      "2017019880019_wonsonghee_0.npy 4\n",
      "2017019880020\n",
      "2017019880020_yoonhyeeun_4.npy 0\n",
      "2017019880020_yoonhyeeun_1.npy 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017019880020_yoonhyeeun_0.npy 2\n",
      "2017019880020_yoonhyeeun_2.npy 3\n",
      "2017019880020_yoonhyeeun_3.npy 4\n",
      "2017019880021\n",
      "2017019880021_kimjuyeong_3.npy 0\n",
      "2017019880021_kimjuyeong_4.npy 1\n",
      "2017019880021_kimjuyeong_1.npy 2\n",
      "2017019880021_kimjuyeong_2.npy 3\n",
      "2017019880021_kimjuyeong_0.npy 4\n",
      "2017019880022\n",
      "2017019880022_kimjaein_3.npy 0\n",
      "2017019880022_kimjaein_0.npy 1\n",
      "2017019880022_kimjaein_4.npy 2\n",
      "2017019880022_kimjaein_1.npy 3\n",
      "2017019880022_kimjaein_2.npy 4\n",
      "2017019880023\n",
      "2017019880023_yoohaekyung_0.npy 0\n",
      "2017019880023_yoohaekyung_4.npy 1\n",
      "2017019880023_yoohaekyung_2.npy 2\n",
      "2017019880023_yoohaekyung_1.npy 3\n",
      "2017019880023_yoohaekyung_3.npy 4\n",
      "2017019880024\n",
      "2017019880024_hanyukyung_2.npy 0\n",
      "2017019880024_hanyukyung_0.npy 1\n",
      "2017019880024_hanyukyung_4.npy 2\n",
      "2017019880024_hanyukyung_1.npy 3\n",
      "2017019880024_hanyukyung_3.npy 4\n",
      "2017019880025\n",
      "2017019880025_yoojungkyun_3.npy 0\n",
      "2017019880025_yoojungkyun_2.npy 1\n",
      "2017019880025_yoojungkyun_0.npy 2\n",
      "2017019880025_yoojungkyun_1.npy 3\n",
      "2017019880025_yoojungkyun_4.npy 4\n",
      "2017019880026\n",
      "2017019880026_parkjongsang_1.npy 0\n",
      "2017019880026_parkjongsang_0.npy 1\n",
      "2017019880026_parkjongsang_2.npy 2\n",
      "2017019880026_parkjongsang_4.npy 3\n",
      "2017019880026_parkjongsang_3.npy 4\n",
      "2017019880027\n",
      "2017019880027_leesol_3.npy 0\n",
      "2017019880027_leesol_2.npy 1\n",
      "2017019880027_leesol_0.npy 2\n",
      "2017019880027_leesol_1.npy 3\n",
      "2017019880027_leesol_4.npy 4\n",
      "2017019880028\n",
      "2017019880028_kimsunghan_3.npy 0\n",
      "2017019880028_kimsunghan_0.npy 1\n",
      "2017019880028_kimsunghan_2.npy 2\n",
      "2017019880028_kimsunghan_1.npy 3\n",
      "2017019880028_kimsunghan_4.npy 4\n",
      "2017019880029\n",
      "2017019880029_kimminji_4.npy 0\n",
      "2017019880029_kimminji_1.npy 1\n",
      "2017019880029_kimminji_3.npy 2\n",
      "2017019880029_kimminji_0.npy 3\n",
      "2017019880029_kimminji_2.npy 4\n",
      "2017019880030\n",
      "2017019880030_hanseungoh_2.npy 0\n",
      "2017019880030_hanseungoh_1.npy 1\n",
      "2017019880030_hanseungoh_3.npy 2\n",
      "2017019880030_hanseungoh_4.npy 3\n",
      "2017019880030_hanseungoh_0.npy 4\n",
      "2017019880031\n",
      "2017019880031_ahnjiwoo_4.npy 0\n",
      "2017019880031_ahnjiwoo_2.npy 1\n",
      "2017019880031_ahnjiwoo_1.npy 2\n",
      "2017019880031_ahnjiwoo_3.npy 3\n",
      "2017019880031_ahnjiwoo_0.npy 4\n",
      "<class 'numpy.ndarray'>\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97]\n"
     ]
    }
   ],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "fname_list =[]\n",
    "for i in range(0,len(class_names)):\n",
    "    files=os.listdir(\"../../feature/feature_logscale_stft/\"+class_names[i])\n",
    "    files = [file for file in files if file.endswith(\".npy\")]\n",
    "    print(class_names[i].split('_')[0])\n",
    "\n",
    "    for j in range(0, len(files)):\n",
    "        print(files[j], j)\n",
    "        x = np.load(\"../../feature/feature_logscale_stft/\"+class_names[i]+\"/\"+files[j])\n",
    "        fname_list.append(\"../../feature/feature_logscale_stft/\"+class_names[i]+\"/\"+files[j])\n",
    "        x_list.append(x)\n",
    "        y_list.append(i)\n",
    "print(type(x))\n",
    "print(y_list)\n",
    "# print(x_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Feature Numpy Array to PNG image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "def npy_2_png (cname,fname):\n",
    "    if not os.path.exists(\"../../feature/feature_logscale_stft_png/\"):\n",
    "        os.makedirs(\"../../feature/feature_logscale_stft_png/\")\n",
    "    if not os.path.exists(\"../../feature/feature_logscale_stft_png/\"+cname) :\n",
    "        os.makedirs(\"../../feature/feature_logscale_stft_png/\"+cname)\n",
    "    \n",
    "    array = np.load(\"../../feature/feature_logscale_stft/\"+cname+\"/\"+fname)\n",
    "    \n",
    "    array = array - np.min(array)\n",
    "    array = array / np.max(array)\n",
    "    array = array * 255.0\n",
    "\n",
    "    i = fname.split('_')[2].split('.')[0]\n",
    "#     if os.path.exists(\"../../feature/feature_logscale_stft_png/\"+cname+\"/{}.png\".format(i)):\n",
    "#         os.remove(\"../../feature/feature_logscale_stft_png/\"+cname+\"/{}.png\".format(i))\n",
    "    if not os.path.exists(\"../../feature/feature_logscale_stft_png/\"+cname+\"/{}.png\".format(i)):\n",
    "        imageio.imwrite(\"../../feature/feature_logscale_stft_png/\"+cname+\"/{}.png\".format(i),array)\n",
    "        \n",
    "    return \"../../feature/feature_logscale_stft_png/\"+cname+\"/{}.png\".format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../../feature/feature_logscale_stft/2017019740001_kwakjuheon/2017019740001_kwakjuheon_4.npy\n",
      "1 ../../feature/feature_logscale_stft/2017019740001_kwakjuheon/2017019740001_kwakjuheon_1.npy\n",
      "2 ../../feature/feature_logscale_stft/2017019740001_kwakjuheon/2017019740001_kwakjuheon_0.npy\n",
      "3 ../../feature/feature_logscale_stft/2017019740001_kwakjuheon/2017019740001_kwakjuheon_2.npy\n",
      "4 ../../feature/feature_logscale_stft/2017019740001_kwakjuheon/2017019740001_kwakjuheon_3.npy\n",
      "5 ../../feature/feature_logscale_stft/2017019740002_kimjiho/2017019740002_kimjiho_3.npy\n",
      "6 ../../feature/feature_logscale_stft/2017019740002_kimjiho/2017019740002_kimjiho_1.npy\n",
      "7 ../../feature/feature_logscale_stft/2017019740002_kimjiho/2017019740002_kimjiho_2.npy\n",
      "8 ../../feature/feature_logscale_stft/2017019740002_kimjiho/2017019740002_kimjiho_4.npy\n",
      "9 ../../feature/feature_logscale_stft/2017019740002_kimjiho/2017019740002_kimjiho_0.npy\n",
      "10 ../../feature/feature_logscale_stft/2017019740003_songyejin/2017019740003_songyejin_2.npy\n",
      "11 ../../feature/feature_logscale_stft/2017019740003_songyejin/2017019740003_songyejin_3.npy\n",
      "12 ../../feature/feature_logscale_stft/2017019740003_songyejin/2017019740003_songyejin_4.npy\n",
      "13 ../../feature/feature_logscale_stft/2017019740003_songyejin/2017019740003_songyejin_1.npy\n",
      "14 ../../feature/feature_logscale_stft/2017019740003_songyejin/2017019740003_songyejin_0.npy\n",
      "15 ../../feature/feature_logscale_stft/2017019740004_parksohui/2017019740004_parksohui_2.npy\n",
      "16 ../../feature/feature_logscale_stft/2017019740004_parksohui/2017019740004_parksohui_1.npy\n",
      "17 ../../feature/feature_logscale_stft/2017019740004_parksohui/2017019740004_parksohui_3.npy\n",
      "18 ../../feature/feature_logscale_stft/2017019740004_parksohui/2017019740004_parksohui_0.npy\n",
      "19 ../../feature/feature_logscale_stft/2017019740004_parksohui/2017019740004_parksohui_4.npy\n",
      "20 ../../feature/feature_logscale_stft/2017019740005_moonyeonwoo/2017019740005_moonyeonwoo_3.npy\n",
      "21 ../../feature/feature_logscale_stft/2017019740005_moonyeonwoo/2017019740005_moonyeonwoo_2.npy\n",
      "22 ../../feature/feature_logscale_stft/2017019740005_moonyeonwoo/2017019740005_moonyeonwoo_0.npy\n",
      "23 ../../feature/feature_logscale_stft/2017019740005_moonyeonwoo/2017019740005_moonyeonwoo_4.npy\n",
      "24 ../../feature/feature_logscale_stft/2017019740005_moonyeonwoo/2017019740005_moonyeonwoo_1.npy\n",
      "25 ../../feature/feature_logscale_stft/2017019740006_kangsubin/2017019740006_kangsubin_3.npy\n",
      "26 ../../feature/feature_logscale_stft/2017019740006_kangsubin/2017019740006_kangsubin_1.npy\n",
      "27 ../../feature/feature_logscale_stft/2017019740006_kangsubin/2017019740006_kangsubin_4.npy\n",
      "28 ../../feature/feature_logscale_stft/2017019740006_kangsubin/2017019740006_kangsubin_2.npy\n",
      "29 ../../feature/feature_logscale_stft/2017019740006_kangsubin/2017019740006_kangsubin_0.npy\n",
      "30 ../../feature/feature_logscale_stft/2017019740007_leekyeongeun/2017019740007_leekyeongeun_2.npy\n",
      "31 ../../feature/feature_logscale_stft/2017019740007_leekyeongeun/2017019740007_leekyeongeun_4.npy\n",
      "32 ../../feature/feature_logscale_stft/2017019740007_leekyeongeun/2017019740007_leekyeongeun_0.npy\n",
      "33 ../../feature/feature_logscale_stft/2017019740007_leekyeongeun/2017019740007_leekyeongeun_3.npy\n",
      "34 ../../feature/feature_logscale_stft/2017019740007_leekyeongeun/2017019740007_leekyeongeun_1.npy\n",
      "35 ../../feature/feature_logscale_stft/2017019740008_chochaeyeon/2017019740008_chochaeyeon_4.npy\n",
      "36 ../../feature/feature_logscale_stft/2017019740008_chochaeyeon/2017019740008_chochaeyeon_3.npy\n",
      "37 ../../feature/feature_logscale_stft/2017019740008_chochaeyeon/2017019740008_chochaeyeon_2.npy\n",
      "38 ../../feature/feature_logscale_stft/2017019740008_chochaeyeon/2017019740008_chochaeyeon_1.npy\n",
      "39 ../../feature/feature_logscale_stft/2017019740008_chochaeyeon/2017019740008_chochaeyeon_0.npy\n",
      "40 ../../feature/feature_logscale_stft/2017019740009_shindonghwan/2017019740009_shindonghwan_1.npy\n",
      "41 ../../feature/feature_logscale_stft/2017019740009_shindonghwan/2017019740009_shindonghwan_2.npy\n",
      "42 ../../feature/feature_logscale_stft/2017019740009_shindonghwan/2017019740009_shindonghwan_4.npy\n",
      "43 ../../feature/feature_logscale_stft/2017019740009_shindonghwan/2017019740009_shindonghwan_0.npy\n",
      "44 ../../feature/feature_logscale_stft/2017019740009_shindonghwan/2017019740009_shindonghwan_3.npy\n",
      "45 ../../feature/feature_logscale_stft/2017019740010_kwakmirae/2017019740010_kwakmirae_4.npy\n",
      "46 ../../feature/feature_logscale_stft/2017019740010_kwakmirae/2017019740010_kwakmirae_0.npy\n",
      "47 ../../feature/feature_logscale_stft/2017019740010_kwakmirae/2017019740010_kwakmirae_1.npy\n",
      "48 ../../feature/feature_logscale_stft/2017019740010_kwakmirae/2017019740010_kwakmirae_2.npy\n",
      "49 ../../feature/feature_logscale_stft/2017019740010_kwakmirae/2017019740010_kwakmirae_3.npy\n",
      "50 ../../feature/feature_logscale_stft/2017019740011_kimhyeryeong/2017019740011_kimhyeryeong_1.npy\n",
      "51 ../../feature/feature_logscale_stft/2017019740011_kimhyeryeong/2017019740011_kimhyeryeong_3.npy\n",
      "52 ../../feature/feature_logscale_stft/2017019740011_kimhyeryeong/2017019740011_kimhyeryeong_0.npy\n",
      "53 ../../feature/feature_logscale_stft/2017019740011_kimhyeryeong/2017019740011_kimhyeryeong_4.npy\n",
      "54 ../../feature/feature_logscale_stft/2017019740011_kimhyeryeong/2017019740011_kimhyeryeong_2.npy\n",
      "55 ../../feature/feature_logscale_stft/2017019740012_chaeminjoon/2017019740012_chaeminjoon_0.npy\n",
      "56 ../../feature/feature_logscale_stft/2017019740012_chaeminjoon/2017019740012_chaeminjoon_4.npy\n",
      "57 ../../feature/feature_logscale_stft/2017019740012_chaeminjoon/2017019740012_chaeminjoon_1.npy\n",
      "58 ../../feature/feature_logscale_stft/2017019740012_chaeminjoon/2017019740012_chaeminjoon_2.npy\n",
      "59 ../../feature/feature_logscale_stft/2017019740012_chaeminjoon/2017019740012_chaeminjoon_3.npy\n",
      "60 ../../feature/feature_logscale_stft/2017019740013_kwakyiheon/2017019740013_kwakyiheon_0.npy\n",
      "61 ../../feature/feature_logscale_stft/2017019740013_kwakyiheon/2017019740013_kwakyiheon_1.npy\n",
      "62 ../../feature/feature_logscale_stft/2017019740013_kwakyiheon/2017019740013_kwakyiheon_4.npy\n",
      "63 ../../feature/feature_logscale_stft/2017019740013_kwakyiheon/2017019740013_kwakyiheon_2.npy\n",
      "64 ../../feature/feature_logscale_stft/2017019740013_kwakyiheon/2017019740013_kwakyiheon_3.npy\n",
      "65 ../../feature/feature_logscale_stft/2017019740014_leesumin/2017019740014_leesumin_0.npy\n",
      "66 ../../feature/feature_logscale_stft/2017019740014_leesumin/2017019740014_leesumin_4.npy\n",
      "67 ../../feature/feature_logscale_stft/2017019740014_leesumin/2017019740014_leesumin_2.npy\n",
      "68 ../../feature/feature_logscale_stft/2017019740014_leesumin/2017019740014_leesumin_1.npy\n",
      "69 ../../feature/feature_logscale_stft/2017019740014_leesumin/2017019740014_leesumin_3.npy\n",
      "70 ../../feature/feature_logscale_stft/2017019740015_choihayoung/2017019740015_choihayoung_3.npy\n",
      "71 ../../feature/feature_logscale_stft/2017019740015_choihayoung/2017019740015_choihayoung_1.npy\n",
      "72 ../../feature/feature_logscale_stft/2017019740015_choihayoung/2017019740015_choihayoung_4.npy\n",
      "73 ../../feature/feature_logscale_stft/2017019740015_choihayoung/2017019740015_choihayoung_2.npy\n",
      "74 ../../feature/feature_logscale_stft/2017019740015_choihayoung/2017019740015_choihayoung_0.npy\n",
      "75 ../../feature/feature_logscale_stft/2017019740016_kangyeseo/2017019740016_kangyeseo_0.npy\n",
      "76 ../../feature/feature_logscale_stft/2017019740016_kangyeseo/2017019740016_kangyeseo_3.npy\n",
      "77 ../../feature/feature_logscale_stft/2017019740016_kangyeseo/2017019740016_kangyeseo_2.npy\n",
      "78 ../../feature/feature_logscale_stft/2017019740016_kangyeseo/2017019740016_kangyeseo_4.npy\n",
      "79 ../../feature/feature_logscale_stft/2017019740016_kangyeseo/2017019740016_kangyeseo_1.npy\n",
      "80 ../../feature/feature_logscale_stft/2017019740017_kwakmihyang/2017019740017_kwakmihyang_3.npy\n",
      "81 ../../feature/feature_logscale_stft/2017019740017_kwakmihyang/2017019740017_kwakmihyang_2.npy\n",
      "82 ../../feature/feature_logscale_stft/2017019740017_kwakmihyang/2017019740017_kwakmihyang_1.npy\n",
      "83 ../../feature/feature_logscale_stft/2017019740017_kwakmihyang/2017019740017_kwakmihyang_4.npy\n",
      "84 ../../feature/feature_logscale_stft/2017019740017_kwakmihyang/2017019740017_kwakmihyang_0.npy\n",
      "85 ../../feature/feature_logscale_stft/2017019740018_eundano/2017019740018_eundano_0.npy\n",
      "86 ../../feature/feature_logscale_stft/2017019740018_eundano/2017019740018_eundano_4.npy\n",
      "87 ../../feature/feature_logscale_stft/2017019740018_eundano/2017019740018_eundano_1.npy\n",
      "88 ../../feature/feature_logscale_stft/2017019740018_eundano/2017019740018_eundano_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 ../../feature/feature_logscale_stft/2017019740018_eundano/2017019740018_eundano_2.npy\n",
      "90 ../../feature/feature_logscale_stft/2017019740019_limjinju/2017019740019_limjinju_1.npy\n",
      "91 ../../feature/feature_logscale_stft/2017019740019_limjinju/2017019740019_limjinju_3.npy\n",
      "92 ../../feature/feature_logscale_stft/2017019740019_limjinju/2017019740019_limjinju_4.npy\n",
      "93 ../../feature/feature_logscale_stft/2017019740019_limjinju/2017019740019_limjinju_2.npy\n",
      "94 ../../feature/feature_logscale_stft/2017019740019_limjinju/2017019740019_limjinju_0.npy\n",
      "95 ../../feature/feature_logscale_stft/2017019740020_kimseongje/2017019740020_kimseongje_3.npy\n",
      "96 ../../feature/feature_logscale_stft/2017019740020_kimseongje/2017019740020_kimseongje_1.npy\n",
      "97 ../../feature/feature_logscale_stft/2017019740020_kimseongje/2017019740020_kimseongje_4.npy\n",
      "98 ../../feature/feature_logscale_stft/2017019740020_kimseongje/2017019740020_kimseongje_2.npy\n",
      "99 ../../feature/feature_logscale_stft/2017019740020_kimseongje/2017019740020_kimseongje_0.npy\n",
      "100 ../../feature/feature_logscale_stft/2017019740021_kwakbokyeong/2017019740021_kwakbokyeong_3.npy\n",
      "101 ../../feature/feature_logscale_stft/2017019740021_kwakbokyeong/2017019740021_kwakbokyeong_2.npy\n",
      "102 ../../feature/feature_logscale_stft/2017019740021_kwakbokyeong/2017019740021_kwakbokyeong_0.npy\n",
      "103 ../../feature/feature_logscale_stft/2017019740021_kwakbokyeong/2017019740021_kwakbokyeong_1.npy\n",
      "104 ../../feature/feature_logscale_stft/2017019740021_kwakbokyeong/2017019740021_kwakbokyeong_4.npy\n",
      "105 ../../feature/feature_logscale_stft/2017019740022_ahnhyojin/2017019740022_ahnhyojin_0.npy\n",
      "106 ../../feature/feature_logscale_stft/2017019740022_ahnhyojin/2017019740022_ahnhyojin_1.npy\n",
      "107 ../../feature/feature_logscale_stft/2017019740022_ahnhyojin/2017019740022_ahnhyojin_2.npy\n",
      "108 ../../feature/feature_logscale_stft/2017019740022_ahnhyojin/2017019740022_ahnhyojin_3.npy\n",
      "109 ../../feature/feature_logscale_stft/2017019740022_ahnhyojin/2017019740022_ahnhyojin_4.npy\n",
      "110 ../../feature/feature_logscale_stft/2017019740023_heosehun/2017019740023_heosehun_3.npy\n",
      "111 ../../feature/feature_logscale_stft/2017019740023_heosehun/2017019740023_heosehun_0.npy\n",
      "112 ../../feature/feature_logscale_stft/2017019740023_heosehun/2017019740023_heosehun_4.npy\n",
      "113 ../../feature/feature_logscale_stft/2017019740023_heosehun/2017019740023_heosehun_2.npy\n",
      "114 ../../feature/feature_logscale_stft/2017019740023_heosehun/2017019740023_heosehun_1.npy\n",
      "115 ../../feature/feature_logscale_stft/2017019740024_choijiwon/2017019740024_choijiwon_2.npy\n",
      "116 ../../feature/feature_logscale_stft/2017019740024_choijiwon/2017019740024_choijiwon_0.npy\n",
      "117 ../../feature/feature_logscale_stft/2017019740024_choijiwon/2017019740024_choijiwon_3.npy\n",
      "118 ../../feature/feature_logscale_stft/2017019740024_choijiwon/2017019740024_choijiwon_1.npy\n",
      "119 ../../feature/feature_logscale_stft/2017019740024_choijiwon/2017019740024_choijiwon_4.npy\n",
      "120 ../../feature/feature_logscale_stft/2017019740025_ahnjeongsuk/2017019740025_ahnjeongsuk_2.npy\n",
      "121 ../../feature/feature_logscale_stft/2017019740025_ahnjeongsuk/2017019740025_ahnjeongsuk_4.npy\n",
      "122 ../../feature/feature_logscale_stft/2017019740025_ahnjeongsuk/2017019740025_ahnjeongsuk_1.npy\n",
      "123 ../../feature/feature_logscale_stft/2017019740025_ahnjeongsuk/2017019740025_ahnjeongsuk_0.npy\n",
      "124 ../../feature/feature_logscale_stft/2017019740025_ahnjeongsuk/2017019740025_ahnjeongsuk_3.npy\n",
      "125 ../../feature/feature_logscale_stft/2017019740026_parkyeongseon/2017019740026_parkyeongseon_1.npy\n",
      "126 ../../feature/feature_logscale_stft/2017019740026_parkyeongseon/2017019740026_parkyeongseon_0.npy\n",
      "127 ../../feature/feature_logscale_stft/2017019740026_parkyeongseon/2017019740026_parkyeongseon_2.npy\n",
      "128 ../../feature/feature_logscale_stft/2017019740026_parkyeongseon/2017019740026_parkyeongseon_4.npy\n",
      "129 ../../feature/feature_logscale_stft/2017019740026_parkyeongseon/2017019740026_parkyeongseon_3.npy\n",
      "130 ../../feature/feature_logscale_stft/2017019740027_kwaksangpil/2017019740027_kwaksangpil_1.npy\n",
      "131 ../../feature/feature_logscale_stft/2017019740027_kwaksangpil/2017019740027_kwaksangpil_3.npy\n",
      "132 ../../feature/feature_logscale_stft/2017019740027_kwaksangpil/2017019740027_kwaksangpil_2.npy\n",
      "133 ../../feature/feature_logscale_stft/2017019740027_kwaksangpil/2017019740027_kwaksangpil_0.npy\n",
      "134 ../../feature/feature_logscale_stft/2017019740027_kwaksangpil/2017019740027_kwaksangpil_4.npy\n",
      "135 ../../feature/feature_logscale_stft/2017019740028_kodohyeon/2017019740028_kodohyeon_2.npy\n",
      "136 ../../feature/feature_logscale_stft/2017019740028_kodohyeon/2017019740028_kodohyeon_4.npy\n",
      "137 ../../feature/feature_logscale_stft/2017019740028_kodohyeon/2017019740028_kodohyeon_1.npy\n",
      "138 ../../feature/feature_logscale_stft/2017019740028_kodohyeon/2017019740028_kodohyeon_3.npy\n",
      "139 ../../feature/feature_logscale_stft/2017019740028_kodohyeon/2017019740028_kodohyeon_0.npy\n",
      "140 ../../feature/feature_logscale_stft/2017019770001_kwonyuna/2017019770001_kwonyuna_1.npy\n",
      "141 ../../feature/feature_logscale_stft/2017019770001_kwonyuna/2017019770001_kwonyuna_0.npy\n",
      "142 ../../feature/feature_logscale_stft/2017019770001_kwonyuna/2017019770001_kwonyuna_3.npy\n",
      "143 ../../feature/feature_logscale_stft/2017019770001_kwonyuna/2017019770001_kwonyuna_2.npy\n",
      "144 ../../feature/feature_logscale_stft/2017019770001_kwonyuna/2017019770001_kwonyuna_4.npy\n",
      "145 ../../feature/feature_logscale_stft/2017019770002_kwoneunkyung/2017019770002_kwoneunkyung_3.npy\n",
      "146 ../../feature/feature_logscale_stft/2017019770002_kwoneunkyung/2017019770002_kwoneunkyung_2.npy\n",
      "147 ../../feature/feature_logscale_stft/2017019770002_kwoneunkyung/2017019770002_kwoneunkyung_0.npy\n",
      "148 ../../feature/feature_logscale_stft/2017019770002_kwoneunkyung/2017019770002_kwoneunkyung_1.npy\n",
      "149 ../../feature/feature_logscale_stft/2017019770002_kwoneunkyung/2017019770002_kwoneunkyung_4.npy\n",
      "150 ../../feature/feature_logscale_stft/2017019770003_johaesu/2017019770003_johaesu_4.npy\n",
      "151 ../../feature/feature_logscale_stft/2017019770003_johaesu/2017019770003_johaesu_0.npy\n",
      "152 ../../feature/feature_logscale_stft/2017019770003_johaesu/2017019770003_johaesu_1.npy\n",
      "153 ../../feature/feature_logscale_stft/2017019770003_johaesu/2017019770003_johaesu_2.npy\n",
      "154 ../../feature/feature_logscale_stft/2017019770003_johaesu/2017019770003_johaesu_3.npy\n",
      "155 ../../feature/feature_logscale_stft/2017019770004_leebyeongjin/2017019770004_leebyeongjin_4.npy\n",
      "156 ../../feature/feature_logscale_stft/2017019770004_leebyeongjin/2017019770004_leebyeongjin_3.npy\n",
      "157 ../../feature/feature_logscale_stft/2017019770004_leebyeongjin/2017019770004_leebyeongjin_0.npy\n",
      "158 ../../feature/feature_logscale_stft/2017019770004_leebyeongjin/2017019770004_leebyeongjin_2.npy\n",
      "159 ../../feature/feature_logscale_stft/2017019770004_leebyeongjin/2017019770004_leebyeongjin_1.npy\n",
      "160 ../../feature/feature_logscale_stft/2017019770005_hyeonsanghyeok/2017019770005_hyeonsanghyeok_1.npy\n",
      "161 ../../feature/feature_logscale_stft/2017019770005_hyeonsanghyeok/2017019770005_hyeonsanghyeok_2.npy\n",
      "162 ../../feature/feature_logscale_stft/2017019770005_hyeonsanghyeok/2017019770005_hyeonsanghyeok_4.npy\n",
      "163 ../../feature/feature_logscale_stft/2017019770005_hyeonsanghyeok/2017019770005_hyeonsanghyeok_0.npy\n",
      "164 ../../feature/feature_logscale_stft/2017019770005_hyeonsanghyeok/2017019770005_hyeonsanghyeok_3.npy\n",
      "165 ../../feature/feature_logscale_stft/2017019770006_jennie/2017019770006_jennie_4.npy\n",
      "166 ../../feature/feature_logscale_stft/2017019770006_jennie/2017019770006_jennie_0.npy\n",
      "167 ../../feature/feature_logscale_stft/2017019770006_jennie/2017019770006_jennie_1.npy\n",
      "168 ../../feature/feature_logscale_stft/2017019770006_jennie/2017019770006_jennie_2.npy\n",
      "169 ../../feature/feature_logscale_stft/2017019770006_jennie/2017019770006_jennie_3.npy\n",
      "170 ../../feature/feature_logscale_stft/2017019770007_simseungmin/2017019770007_simseungmin_3.npy\n",
      "171 ../../feature/feature_logscale_stft/2017019770007_simseungmin/2017019770007_simseungmin_2.npy\n",
      "172 ../../feature/feature_logscale_stft/2017019770007_simseungmin/2017019770007_simseungmin_1.npy\n",
      "173 ../../feature/feature_logscale_stft/2017019770007_simseungmin/2017019770007_simseungmin_4.npy\n",
      "174 ../../feature/feature_logscale_stft/2017019770007_simseungmin/2017019770007_simseungmin_0.npy\n",
      "175 ../../feature/feature_logscale_stft/2017019770008_parksomi/2017019770008_parksomi_2.npy\n",
      "176 ../../feature/feature_logscale_stft/2017019770008_parksomi/2017019770008_parksomi_1.npy\n",
      "177 ../../feature/feature_logscale_stft/2017019770008_parksomi/2017019770008_parksomi_3.npy\n",
      "178 ../../feature/feature_logscale_stft/2017019770008_parksomi/2017019770008_parksomi_0.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 ../../feature/feature_logscale_stft/2017019770008_parksomi/2017019770008_parksomi_4.npy\n",
      "180 ../../feature/feature_logscale_stft/2017019770009_yuminji/2017019770009_yuminji_3.npy\n",
      "181 ../../feature/feature_logscale_stft/2017019770009_yuminji/2017019770009_yuminji_4.npy\n",
      "182 ../../feature/feature_logscale_stft/2017019770009_yuminji/2017019770009_yuminji_0.npy\n",
      "183 ../../feature/feature_logscale_stft/2017019770009_yuminji/2017019770009_yuminji_1.npy\n",
      "184 ../../feature/feature_logscale_stft/2017019770009_yuminji/2017019770009_yuminji_2.npy\n",
      "185 ../../feature/feature_logscale_stft/2017019770010_parksojin/2017019770010_parksojin_1.npy\n",
      "186 ../../feature/feature_logscale_stft/2017019770010_parksojin/2017019770010_parksojin_4.npy\n",
      "187 ../../feature/feature_logscale_stft/2017019770010_parksojin/2017019770010_parksojin_0.npy\n",
      "188 ../../feature/feature_logscale_stft/2017019770010_parksojin/2017019770010_parksojin_3.npy\n",
      "189 ../../feature/feature_logscale_stft/2017019770010_parksojin/2017019770010_parksojin_2.npy\n",
      "190 ../../feature/feature_logscale_stft/2017019770011_kwonyeonwoo/2017019770011_kwonyeonwoo_0.npy\n",
      "191 ../../feature/feature_logscale_stft/2017019770011_kwonyeonwoo/2017019770011_kwonyeonwoo_2.npy\n",
      "192 ../../feature/feature_logscale_stft/2017019770011_kwonyeonwoo/2017019770011_kwonyeonwoo_3.npy\n",
      "193 ../../feature/feature_logscale_stft/2017019770011_kwonyeonwoo/2017019770011_kwonyeonwoo_4.npy\n",
      "194 ../../feature/feature_logscale_stft/2017019770011_kwonyeonwoo/2017019770011_kwonyeonwoo_1.npy\n",
      "195 ../../feature/feature_logscale_stft/2017019770012_ladakyeong/2017019770012_ladakyeong_1.npy\n",
      "196 ../../feature/feature_logscale_stft/2017019770012_ladakyeong/2017019770012_ladakyeong_4.npy\n",
      "197 ../../feature/feature_logscale_stft/2017019770012_ladakyeong/2017019770012_ladakyeong_3.npy\n",
      "198 ../../feature/feature_logscale_stft/2017019770012_ladakyeong/2017019770012_ladakyeong_0.npy\n",
      "199 ../../feature/feature_logscale_stft/2017019770012_ladakyeong/2017019770012_ladakyeong_2.npy\n",
      "200 ../../feature/feature_logscale_stft/2017019770013_janghyomin/2017019770013_janghyomin_2.npy\n",
      "201 ../../feature/feature_logscale_stft/2017019770013_janghyomin/2017019770013_janghyomin_3.npy\n",
      "202 ../../feature/feature_logscale_stft/2017019770013_janghyomin/2017019770013_janghyomin_0.npy\n",
      "203 ../../feature/feature_logscale_stft/2017019770013_janghyomin/2017019770013_janghyomin_1.npy\n",
      "204 ../../feature/feature_logscale_stft/2017019770013_janghyomin/2017019770013_janghyomin_4.npy\n",
      "205 ../../feature/feature_logscale_stft/2017019770014_parkeunbi/2017019770014_parkeunbi_3.npy\n",
      "206 ../../feature/feature_logscale_stft/2017019770014_parkeunbi/2017019770014_parkeunbi_2.npy\n",
      "207 ../../feature/feature_logscale_stft/2017019770014_parkeunbi/2017019770014_parkeunbi_0.npy\n",
      "208 ../../feature/feature_logscale_stft/2017019770014_parkeunbi/2017019770014_parkeunbi_1.npy\n",
      "209 ../../feature/feature_logscale_stft/2017019770014_parkeunbi/2017019770014_parkeunbi_4.npy\n",
      "210 ../../feature/feature_logscale_stft/2017019770015_parkdayeung/2017019770015_parkdayeung_4.npy\n",
      "211 ../../feature/feature_logscale_stft/2017019770015_parkdayeung/2017019770015_parkdayeung_2.npy\n",
      "212 ../../feature/feature_logscale_stft/2017019770015_parkdayeung/2017019770015_parkdayeung_3.npy\n",
      "213 ../../feature/feature_logscale_stft/2017019770015_parkdayeung/2017019770015_parkdayeung_1.npy\n",
      "214 ../../feature/feature_logscale_stft/2017019770015_parkdayeung/2017019770015_parkdayeung_0.npy\n",
      "215 ../../feature/feature_logscale_stft/2017019770016_parkjongae/2017019770016_parkjongae_4.npy\n",
      "216 ../../feature/feature_logscale_stft/2017019770016_parkjongae/2017019770016_parkjongae_2.npy\n",
      "217 ../../feature/feature_logscale_stft/2017019770016_parkjongae/2017019770016_parkjongae_3.npy\n",
      "218 ../../feature/feature_logscale_stft/2017019770016_parkjongae/2017019770016_parkjongae_0.npy\n",
      "219 ../../feature/feature_logscale_stft/2017019770016_parkjongae/2017019770016_parkjongae_1.npy\n",
      "220 ../../feature/feature_logscale_stft/2017019770017_hansohee/2017019770017_hansohee_3.npy\n",
      "221 ../../feature/feature_logscale_stft/2017019770017_hansohee/2017019770017_hansohee_1.npy\n",
      "222 ../../feature/feature_logscale_stft/2017019770017_hansohee/2017019770017_hansohee_0.npy\n",
      "223 ../../feature/feature_logscale_stft/2017019770017_hansohee/2017019770017_hansohee_2.npy\n",
      "224 ../../feature/feature_logscale_stft/2017019770017_hansohee/2017019770017_hansohee_4.npy\n",
      "225 ../../feature/feature_logscale_stft/2017019770018_janggyeoul/2017019770018_janggyeoul_4.npy\n",
      "226 ../../feature/feature_logscale_stft/2017019770018_janggyeoul/2017019770018_janggyeoul_3.npy\n",
      "227 ../../feature/feature_logscale_stft/2017019770018_janggyeoul/2017019770018_janggyeoul_2.npy\n",
      "228 ../../feature/feature_logscale_stft/2017019770018_janggyeoul/2017019770018_janggyeoul_1.npy\n",
      "229 ../../feature/feature_logscale_stft/2017019770018_janggyeoul/2017019770018_janggyeoul_0.npy\n",
      "230 ../../feature/feature_logscale_stft/2017019770019_leewooju/2017019770019_leewooju_3.npy\n",
      "231 ../../feature/feature_logscale_stft/2017019770019_leewooju/2017019770019_leewooju_4.npy\n",
      "232 ../../feature/feature_logscale_stft/2017019770019_leewooju/2017019770019_leewooju_1.npy\n",
      "233 ../../feature/feature_logscale_stft/2017019770019_leewooju/2017019770019_leewooju_2.npy\n",
      "234 ../../feature/feature_logscale_stft/2017019770019_leewooju/2017019770019_leewooju_0.npy\n",
      "235 ../../feature/feature_logscale_stft/2017019770020_nomyungok/2017019770020_nomyungok_4.npy\n",
      "236 ../../feature/feature_logscale_stft/2017019770020_nomyungok/2017019770020_nomyungok_1.npy\n",
      "237 ../../feature/feature_logscale_stft/2017019770020_nomyungok/2017019770020_nomyungok_0.npy\n",
      "238 ../../feature/feature_logscale_stft/2017019770020_nomyungok/2017019770020_nomyungok_2.npy\n",
      "239 ../../feature/feature_logscale_stft/2017019770020_nomyungok/2017019770020_nomyungok_3.npy\n",
      "240 ../../feature/feature_logscale_stft/2017019770021_heoyoonjung/2017019770021_heoyoonjung_4.npy\n",
      "241 ../../feature/feature_logscale_stft/2017019770021_heoyoonjung/2017019770021_heoyoonjung_2.npy\n",
      "242 ../../feature/feature_logscale_stft/2017019770021_heoyoonjung/2017019770021_heoyoonjung_3.npy\n",
      "243 ../../feature/feature_logscale_stft/2017019770021_heoyoonjung/2017019770021_heoyoonjung_1.npy\n",
      "244 ../../feature/feature_logscale_stft/2017019770021_heoyoonjung/2017019770021_heoyoonjung_0.npy\n",
      "245 ../../feature/feature_logscale_stft/2017019770022_heojaemin/2017019770022_heojaemin_4.npy\n",
      "246 ../../feature/feature_logscale_stft/2017019770022_heojaemin/2017019770022_heojaemin_1.npy\n",
      "247 ../../feature/feature_logscale_stft/2017019770022_heojaemin/2017019770022_heojaemin_2.npy\n",
      "248 ../../feature/feature_logscale_stft/2017019770022_heojaemin/2017019770022_heojaemin_0.npy\n",
      "249 ../../feature/feature_logscale_stft/2017019770022_heojaemin/2017019770022_heojaemin_3.npy\n",
      "250 ../../feature/feature_logscale_stft/2017019770023_kimsoyung/2017019770023_kimsoyung_4.npy\n",
      "251 ../../feature/feature_logscale_stft/2017019770023_kimsoyung/2017019770023_kimsoyung_0.npy\n",
      "252 ../../feature/feature_logscale_stft/2017019770023_kimsoyung/2017019770023_kimsoyung_1.npy\n",
      "253 ../../feature/feature_logscale_stft/2017019770023_kimsoyung/2017019770023_kimsoyung_2.npy\n",
      "254 ../../feature/feature_logscale_stft/2017019770023_kimsoyung/2017019770023_kimsoyung_3.npy\n",
      "255 ../../feature/feature_logscale_stft/2017019770024_chuminha/2017019770024_chuminha_0.npy\n",
      "256 ../../feature/feature_logscale_stft/2017019770024_chuminha/2017019770024_chuminha_4.npy\n",
      "257 ../../feature/feature_logscale_stft/2017019770024_chuminha/2017019770024_chuminha_2.npy\n",
      "258 ../../feature/feature_logscale_stft/2017019770024_chuminha/2017019770024_chuminha_3.npy\n",
      "259 ../../feature/feature_logscale_stft/2017019770024_chuminha/2017019770024_chuminha_1.npy\n",
      "260 ../../feature/feature_logscale_stft/2017019770025_kimhyeonsu/2017019770025_kimhyeonsu_1.npy\n",
      "261 ../../feature/feature_logscale_stft/2017019770025_kimhyeonsu/2017019770025_kimhyeonsu_2.npy\n",
      "262 ../../feature/feature_logscale_stft/2017019770025_kimhyeonsu/2017019770025_kimhyeonsu_4.npy\n",
      "263 ../../feature/feature_logscale_stft/2017019770025_kimhyeonsu/2017019770025_kimhyeonsu_0.npy\n",
      "264 ../../feature/feature_logscale_stft/2017019770025_kimhyeonsu/2017019770025_kimhyeonsu_3.npy\n",
      "265 ../../feature/feature_logscale_stft/2017019770026_chaesonghwa/2017019770026_chaesonghwa_2.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 ../../feature/feature_logscale_stft/2017019770026_chaesonghwa/2017019770026_chaesonghwa_0.npy\n",
      "267 ../../feature/feature_logscale_stft/2017019770026_chaesonghwa/2017019770026_chaesonghwa_1.npy\n",
      "268 ../../feature/feature_logscale_stft/2017019770026_chaesonghwa/2017019770026_chaesonghwa_4.npy\n",
      "269 ../../feature/feature_logscale_stft/2017019770026_chaesonghwa/2017019770026_chaesonghwa_3.npy\n",
      "270 ../../feature/feature_logscale_stft/2017019770027_kwonyulim/2017019770027_kwonyulim_2.npy\n",
      "271 ../../feature/feature_logscale_stft/2017019770027_kwonyulim/2017019770027_kwonyulim_3.npy\n",
      "272 ../../feature/feature_logscale_stft/2017019770027_kwonyulim/2017019770027_kwonyulim_4.npy\n",
      "273 ../../feature/feature_logscale_stft/2017019770027_kwonyulim/2017019770027_kwonyulim_1.npy\n",
      "274 ../../feature/feature_logscale_stft/2017019770027_kwonyulim/2017019770027_kwonyulim_0.npy\n",
      "275 ../../feature/feature_logscale_stft/2017019770028_kimminyoung/2017019770028_kimminyoung_3.npy\n",
      "276 ../../feature/feature_logscale_stft/2017019770028_kimminyoung/2017019770028_kimminyoung_2.npy\n",
      "277 ../../feature/feature_logscale_stft/2017019770028_kimminyoung/2017019770028_kimminyoung_4.npy\n",
      "278 ../../feature/feature_logscale_stft/2017019770028_kimminyoung/2017019770028_kimminyoung_0.npy\n",
      "279 ../../feature/feature_logscale_stft/2017019770028_kimminyoung/2017019770028_kimminyoung_1.npy\n",
      "280 ../../feature/feature_logscale_stft/2017019770029_jueunhong/2017019770029_jueunhong_4.npy\n",
      "281 ../../feature/feature_logscale_stft/2017019770029_jueunhong/2017019770029_jueunhong_0.npy\n",
      "282 ../../feature/feature_logscale_stft/2017019770029_jueunhong/2017019770029_jueunhong_3.npy\n",
      "283 ../../feature/feature_logscale_stft/2017019770029_jueunhong/2017019770029_jueunhong_1.npy\n",
      "284 ../../feature/feature_logscale_stft/2017019770029_jueunhong/2017019770029_jueunhong_2.npy\n",
      "285 ../../feature/feature_logscale_stft/2017019770030_leejeongju/2017019770030_leejeongju_1.npy\n",
      "286 ../../feature/feature_logscale_stft/2017019770030_leejeongju/2017019770030_leejeongju_0.npy\n",
      "287 ../../feature/feature_logscale_stft/2017019770030_leejeongju/2017019770030_leejeongju_2.npy\n",
      "288 ../../feature/feature_logscale_stft/2017019770030_leejeongju/2017019770030_leejeongju_4.npy\n",
      "289 ../../feature/feature_logscale_stft/2017019770030_leejeongju/2017019770030_leejeongju_3.npy\n",
      "290 ../../feature/feature_logscale_stft/2017019770031_kwonnahui/2017019770031_kwonnahui_1.npy\n",
      "291 ../../feature/feature_logscale_stft/2017019770031_kwonnahui/2017019770031_kwonnahui_4.npy\n",
      "292 ../../feature/feature_logscale_stft/2017019770031_kwonnahui/2017019770031_kwonnahui_3.npy\n",
      "293 ../../feature/feature_logscale_stft/2017019770031_kwonnahui/2017019770031_kwonnahui_2.npy\n",
      "294 ../../feature/feature_logscale_stft/2017019770031_kwonnahui/2017019770031_kwonnahui_0.npy\n",
      "295 ../../feature/feature_logscale_stft/2017019770032_kimdayeong/2017019770032_kimdayeong_2.npy\n",
      "296 ../../feature/feature_logscale_stft/2017019770032_kimdayeong/2017019770032_kimdayeong_0.npy\n",
      "297 ../../feature/feature_logscale_stft/2017019770032_kimdayeong/2017019770032_kimdayeong_1.npy\n",
      "298 ../../feature/feature_logscale_stft/2017019770032_kimdayeong/2017019770032_kimdayeong_4.npy\n",
      "299 ../../feature/feature_logscale_stft/2017019770032_kimdayeong/2017019770032_kimdayeong_3.npy\n",
      "300 ../../feature/feature_logscale_stft/2017019770033_kwonsundo/2017019770033_kwonsundo_3.npy\n",
      "301 ../../feature/feature_logscale_stft/2017019770033_kwonsundo/2017019770033_kwonsundo_1.npy\n",
      "302 ../../feature/feature_logscale_stft/2017019770033_kwonsundo/2017019770033_kwonsundo_2.npy\n",
      "303 ../../feature/feature_logscale_stft/2017019770033_kwonsundo/2017019770033_kwonsundo_4.npy\n",
      "304 ../../feature/feature_logscale_stft/2017019770033_kwonsundo/2017019770033_kwonsundo_0.npy\n",
      "305 ../../feature/feature_logscale_stft/2017019770034_kimhyeona/2017019770034_kimhyeona_2.npy\n",
      "306 ../../feature/feature_logscale_stft/2017019770034_kimhyeona/2017019770034_kimhyeona_3.npy\n",
      "307 ../../feature/feature_logscale_stft/2017019770034_kimhyeona/2017019770034_kimhyeona_1.npy\n",
      "308 ../../feature/feature_logscale_stft/2017019770034_kimhyeona/2017019770034_kimhyeona_0.npy\n",
      "309 ../../feature/feature_logscale_stft/2017019770034_kimhyeona/2017019770034_kimhyeona_4.npy\n",
      "310 ../../feature/feature_logscale_stft/2017019770035_leehyojin/2017019770035_leehyojin_4.npy\n",
      "311 ../../feature/feature_logscale_stft/2017019770035_leehyojin/2017019770035_leehyojin_1.npy\n",
      "312 ../../feature/feature_logscale_stft/2017019770035_leehyojin/2017019770035_leehyojin_3.npy\n",
      "313 ../../feature/feature_logscale_stft/2017019770035_leehyojin/2017019770035_leehyojin_2.npy\n",
      "314 ../../feature/feature_logscale_stft/2017019770035_leehyojin/2017019770035_leehyojin_0.npy\n",
      "315 ../../feature/feature_logscale_stft/2017019770036_yuminji/2017019770036_yuminji_2.npy\n",
      "316 ../../feature/feature_logscale_stft/2017019770036_yuminji/2017019770036_yuminji_1.npy\n",
      "317 ../../feature/feature_logscale_stft/2017019770036_yuminji/2017019770036_yuminji_3.npy\n",
      "318 ../../feature/feature_logscale_stft/2017019770036_yuminji/2017019770036_yuminji_4.npy\n",
      "319 ../../feature/feature_logscale_stft/2017019770036_yuminji/2017019770036_yuminji_0.npy\n",
      "320 ../../feature/feature_logscale_stft/2017019770037_jeonghojun/2017019770037_jeonghojun_0.npy\n",
      "321 ../../feature/feature_logscale_stft/2017019770037_jeonghojun/2017019770037_jeonghojun_3.npy\n",
      "322 ../../feature/feature_logscale_stft/2017019770037_jeonghojun/2017019770037_jeonghojun_1.npy\n",
      "323 ../../feature/feature_logscale_stft/2017019770037_jeonghojun/2017019770037_jeonghojun_2.npy\n",
      "324 ../../feature/feature_logscale_stft/2017019770037_jeonghojun/2017019770037_jeonghojun_4.npy\n",
      "325 ../../feature/feature_logscale_stft/2017019770038_kanghyeyun/2017019770038_kanghyeyun_1.npy\n",
      "326 ../../feature/feature_logscale_stft/2017019770038_kanghyeyun/2017019770038_kanghyeyun_3.npy\n",
      "327 ../../feature/feature_logscale_stft/2017019770038_kanghyeyun/2017019770038_kanghyeyun_2.npy\n",
      "328 ../../feature/feature_logscale_stft/2017019770038_kanghyeyun/2017019770038_kanghyeyun_0.npy\n",
      "329 ../../feature/feature_logscale_stft/2017019770038_kanghyeyun/2017019770038_kanghyeyun_4.npy\n",
      "330 ../../feature/feature_logscale_stft/2017019770039_ohjiwon/2017019770039_ohjiwon_1.npy\n",
      "331 ../../feature/feature_logscale_stft/2017019770039_ohjiwon/2017019770039_ohjiwon_4.npy\n",
      "332 ../../feature/feature_logscale_stft/2017019770039_ohjiwon/2017019770039_ohjiwon_0.npy\n",
      "333 ../../feature/feature_logscale_stft/2017019770039_ohjiwon/2017019770039_ohjiwon_3.npy\n",
      "334 ../../feature/feature_logscale_stft/2017019770039_ohjiwon/2017019770039_ohjiwon_2.npy\n",
      "335 ../../feature/feature_logscale_stft/2017019880001_kimsubin/2017019880001_kimsubin_1.npy\n",
      "336 ../../feature/feature_logscale_stft/2017019880001_kimsubin/2017019880001_kimsubin_4.npy\n",
      "337 ../../feature/feature_logscale_stft/2017019880001_kimsubin/2017019880001_kimsubin_3.npy\n",
      "338 ../../feature/feature_logscale_stft/2017019880001_kimsubin/2017019880001_kimsubin_0.npy\n",
      "339 ../../feature/feature_logscale_stft/2017019880001_kimsubin/2017019880001_kimsubin_2.npy\n",
      "340 ../../feature/feature_logscale_stft/2017019880002_kimkihyeon/2017019880002_kimkihyeon_0.npy\n",
      "341 ../../feature/feature_logscale_stft/2017019880002_kimkihyeon/2017019880002_kimkihyeon_3.npy\n",
      "342 ../../feature/feature_logscale_stft/2017019880002_kimkihyeon/2017019880002_kimkihyeon_4.npy\n",
      "343 ../../feature/feature_logscale_stft/2017019880002_kimkihyeon/2017019880002_kimkihyeon_2.npy\n",
      "344 ../../feature/feature_logscale_stft/2017019880002_kimkihyeon/2017019880002_kimkihyeon_1.npy\n",
      "345 ../../feature/feature_logscale_stft/2017019880003_kimminji/2017019880003_kimminji_1.npy\n",
      "346 ../../feature/feature_logscale_stft/2017019880003_kimminji/2017019880003_kimminji_4.npy\n",
      "347 ../../feature/feature_logscale_stft/2017019880003_kimminji/2017019880003_kimminji_2.npy\n",
      "348 ../../feature/feature_logscale_stft/2017019880003_kimminji/2017019880003_kimminji_0.npy\n",
      "349 ../../feature/feature_logscale_stft/2017019880003_kimminji/2017019880003_kimminji_3.npy\n",
      "350 ../../feature/feature_logscale_stft/2017019880004_myeongjaewon/2017019880004_myeongjaewon_2.npy\n",
      "351 ../../feature/feature_logscale_stft/2017019880004_myeongjaewon/2017019880004_myeongjaewon_1.npy\n",
      "352 ../../feature/feature_logscale_stft/2017019880004_myeongjaewon/2017019880004_myeongjaewon_0.npy\n",
      "353 ../../feature/feature_logscale_stft/2017019880004_myeongjaewon/2017019880004_myeongjaewon_4.npy\n",
      "354 ../../feature/feature_logscale_stft/2017019880004_myeongjaewon/2017019880004_myeongjaewon_3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 ../../feature/feature_logscale_stft/2017019880005_kimjihyeon/2017019880005_kimjihyeon_1.npy\n",
      "356 ../../feature/feature_logscale_stft/2017019880005_kimjihyeon/2017019880005_kimjihyeon_0.npy\n",
      "357 ../../feature/feature_logscale_stft/2017019880005_kimjihyeon/2017019880005_kimjihyeon_4.npy\n",
      "358 ../../feature/feature_logscale_stft/2017019880005_kimjihyeon/2017019880005_kimjihyeon_3.npy\n",
      "359 ../../feature/feature_logscale_stft/2017019880005_kimjihyeon/2017019880005_kimjihyeon_2.npy\n",
      "360 ../../feature/feature_logscale_stft/2017019880006_choisuyeon/2017019880006_choisuyeon_3.npy\n",
      "361 ../../feature/feature_logscale_stft/2017019880006_choisuyeon/2017019880006_choisuyeon_4.npy\n",
      "362 ../../feature/feature_logscale_stft/2017019880006_choisuyeon/2017019880006_choisuyeon_1.npy\n",
      "363 ../../feature/feature_logscale_stft/2017019880006_choisuyeon/2017019880006_choisuyeon_2.npy\n",
      "364 ../../feature/feature_logscale_stft/2017019880006_choisuyeon/2017019880006_choisuyeon_0.npy\n",
      "365 ../../feature/feature_logscale_stft/2017019880007_hwanghyebin/2017019880007_hwanghyebin_4.npy\n",
      "366 ../../feature/feature_logscale_stft/2017019880007_hwanghyebin/2017019880007_hwanghyebin_2.npy\n",
      "367 ../../feature/feature_logscale_stft/2017019880007_hwanghyebin/2017019880007_hwanghyebin_1.npy\n",
      "368 ../../feature/feature_logscale_stft/2017019880007_hwanghyebin/2017019880007_hwanghyebin_3.npy\n",
      "369 ../../feature/feature_logscale_stft/2017019880007_hwanghyebin/2017019880007_hwanghyebin_0.npy\n",
      "370 ../../feature/feature_logscale_stft/2017019880008_jangsoojin/2017019880008_jangsoojin_3.npy\n",
      "371 ../../feature/feature_logscale_stft/2017019880008_jangsoojin/2017019880008_jangsoojin_0.npy\n",
      "372 ../../feature/feature_logscale_stft/2017019880008_jangsoojin/2017019880008_jangsoojin_1.npy\n",
      "373 ../../feature/feature_logscale_stft/2017019880008_jangsoojin/2017019880008_jangsoojin_2.npy\n",
      "374 ../../feature/feature_logscale_stft/2017019880008_jangsoojin/2017019880008_jangsoojin_4.npy\n",
      "375 ../../feature/feature_logscale_stft/2017019880009_kimhongjoo/2017019880009_kimhongjoo_3.npy\n",
      "376 ../../feature/feature_logscale_stft/2017019880009_kimhongjoo/2017019880009_kimhongjoo_0.npy\n",
      "377 ../../feature/feature_logscale_stft/2017019880009_kimhongjoo/2017019880009_kimhongjoo_1.npy\n",
      "378 ../../feature/feature_logscale_stft/2017019880009_kimhongjoo/2017019880009_kimhongjoo_4.npy\n",
      "379 ../../feature/feature_logscale_stft/2017019880009_kimhongjoo/2017019880009_kimhongjoo_2.npy\n",
      "380 ../../feature/feature_logscale_stft/2017019880010_kimhyorin/2017019880010_kimhyorin_0.npy\n",
      "381 ../../feature/feature_logscale_stft/2017019880010_kimhyorin/2017019880010_kimhyorin_1.npy\n",
      "382 ../../feature/feature_logscale_stft/2017019880010_kimhyorin/2017019880010_kimhyorin_4.npy\n",
      "383 ../../feature/feature_logscale_stft/2017019880010_kimhyorin/2017019880010_kimhyorin_3.npy\n",
      "384 ../../feature/feature_logscale_stft/2017019880010_kimhyorin/2017019880010_kimhyorin_2.npy\n",
      "385 ../../feature/feature_logscale_stft/2017019880011_kimjihyun/2017019880011_kimjihyun_1.npy\n",
      "386 ../../feature/feature_logscale_stft/2017019880011_kimjihyun/2017019880011_kimjihyun_3.npy\n",
      "387 ../../feature/feature_logscale_stft/2017019880011_kimjihyun/2017019880011_kimjihyun_2.npy\n",
      "388 ../../feature/feature_logscale_stft/2017019880011_kimjihyun/2017019880011_kimjihyun_0.npy\n",
      "389 ../../feature/feature_logscale_stft/2017019880011_kimjihyun/2017019880011_kimjihyun_4.npy\n",
      "390 ../../feature/feature_logscale_stft/2017019880012_kimsongyi/2017019880012_kimsongyi_4.npy\n",
      "391 ../../feature/feature_logscale_stft/2017019880012_kimsongyi/2017019880012_kimsongyi_1.npy\n",
      "392 ../../feature/feature_logscale_stft/2017019880012_kimsongyi/2017019880012_kimsongyi_3.npy\n",
      "393 ../../feature/feature_logscale_stft/2017019880012_kimsongyi/2017019880012_kimsongyi_2.npy\n",
      "394 ../../feature/feature_logscale_stft/2017019880012_kimsongyi/2017019880012_kimsongyi_0.npy\n",
      "395 ../../feature/feature_logscale_stft/2017019880013_kotaewan/2017019880013_kotaewan_0.npy\n",
      "396 ../../feature/feature_logscale_stft/2017019880013_kotaewan/2017019880013_kotaewan_1.npy\n",
      "397 ../../feature/feature_logscale_stft/2017019880013_kotaewan/2017019880013_kotaewan_3.npy\n",
      "398 ../../feature/feature_logscale_stft/2017019880013_kotaewan/2017019880013_kotaewan_2.npy\n",
      "399 ../../feature/feature_logscale_stft/2017019880013_kotaewan/2017019880013_kotaewan_4.npy\n",
      "400 ../../feature/feature_logscale_stft/2017019880014_leedanbee/2017019880014_leedanbee_1.npy\n",
      "401 ../../feature/feature_logscale_stft/2017019880014_leedanbee/2017019880014_leedanbee_2.npy\n",
      "402 ../../feature/feature_logscale_stft/2017019880014_leedanbee/2017019880014_leedanbee_4.npy\n",
      "403 ../../feature/feature_logscale_stft/2017019880014_leedanbee/2017019880014_leedanbee_0.npy\n",
      "404 ../../feature/feature_logscale_stft/2017019880014_leedanbee/2017019880014_leedanbee_3.npy\n",
      "405 ../../feature/feature_logscale_stft/2017019880015_leejungjoon/2017019880015_leejungjoon_3.npy\n",
      "406 ../../feature/feature_logscale_stft/2017019880015_leejungjoon/2017019880015_leejungjoon_2.npy\n",
      "407 ../../feature/feature_logscale_stft/2017019880015_leejungjoon/2017019880015_leejungjoon_4.npy\n",
      "408 ../../feature/feature_logscale_stft/2017019880015_leejungjoon/2017019880015_leejungjoon_1.npy\n",
      "409 ../../feature/feature_logscale_stft/2017019880015_leejungjoon/2017019880015_leejungjoon_0.npy\n",
      "410 ../../feature/feature_logscale_stft/2017019880016_parkjongkook/2017019880016_parkjongkook_0.npy\n",
      "411 ../../feature/feature_logscale_stft/2017019880016_parkjongkook/2017019880016_parkjongkook_3.npy\n",
      "412 ../../feature/feature_logscale_stft/2017019880016_parkjongkook/2017019880016_parkjongkook_4.npy\n",
      "413 ../../feature/feature_logscale_stft/2017019880016_parkjongkook/2017019880016_parkjongkook_1.npy\n",
      "414 ../../feature/feature_logscale_stft/2017019880016_parkjongkook/2017019880016_parkjongkook_2.npy\n",
      "415 ../../feature/feature_logscale_stft/2017019880017_sungsoohyun/2017019880017_sungsoohyun_0.npy\n",
      "416 ../../feature/feature_logscale_stft/2017019880017_sungsoohyun/2017019880017_sungsoohyun_1.npy\n",
      "417 ../../feature/feature_logscale_stft/2017019880017_sungsoohyun/2017019880017_sungsoohyun_3.npy\n",
      "418 ../../feature/feature_logscale_stft/2017019880017_sungsoohyun/2017019880017_sungsoohyun_4.npy\n",
      "419 ../../feature/feature_logscale_stft/2017019880017_sungsoohyun/2017019880017_sungsoohyun_2.npy\n",
      "420 ../../feature/feature_logscale_stft/2017019880018_wonjoonho/2017019880018_wonjoonho_4.npy\n",
      "421 ../../feature/feature_logscale_stft/2017019880018_wonjoonho/2017019880018_wonjoonho_0.npy\n",
      "422 ../../feature/feature_logscale_stft/2017019880018_wonjoonho/2017019880018_wonjoonho_3.npy\n",
      "423 ../../feature/feature_logscale_stft/2017019880018_wonjoonho/2017019880018_wonjoonho_1.npy\n",
      "424 ../../feature/feature_logscale_stft/2017019880018_wonjoonho/2017019880018_wonjoonho_2.npy\n",
      "425 ../../feature/feature_logscale_stft/2017019880019_wonsonghee/2017019880019_wonsonghee_2.npy\n",
      "426 ../../feature/feature_logscale_stft/2017019880019_wonsonghee/2017019880019_wonsonghee_3.npy\n",
      "427 ../../feature/feature_logscale_stft/2017019880019_wonsonghee/2017019880019_wonsonghee_4.npy\n",
      "428 ../../feature/feature_logscale_stft/2017019880019_wonsonghee/2017019880019_wonsonghee_1.npy\n",
      "429 ../../feature/feature_logscale_stft/2017019880019_wonsonghee/2017019880019_wonsonghee_0.npy\n",
      "430 ../../feature/feature_logscale_stft/2017019880020_yoonhyeeun/2017019880020_yoonhyeeun_4.npy\n",
      "431 ../../feature/feature_logscale_stft/2017019880020_yoonhyeeun/2017019880020_yoonhyeeun_1.npy\n",
      "432 ../../feature/feature_logscale_stft/2017019880020_yoonhyeeun/2017019880020_yoonhyeeun_0.npy\n",
      "433 ../../feature/feature_logscale_stft/2017019880020_yoonhyeeun/2017019880020_yoonhyeeun_2.npy\n",
      "434 ../../feature/feature_logscale_stft/2017019880020_yoonhyeeun/2017019880020_yoonhyeeun_3.npy\n",
      "435 ../../feature/feature_logscale_stft/2017019880021_kimjuyeong/2017019880021_kimjuyeong_3.npy\n",
      "436 ../../feature/feature_logscale_stft/2017019880021_kimjuyeong/2017019880021_kimjuyeong_4.npy\n",
      "437 ../../feature/feature_logscale_stft/2017019880021_kimjuyeong/2017019880021_kimjuyeong_1.npy\n",
      "438 ../../feature/feature_logscale_stft/2017019880021_kimjuyeong/2017019880021_kimjuyeong_2.npy\n",
      "439 ../../feature/feature_logscale_stft/2017019880021_kimjuyeong/2017019880021_kimjuyeong_0.npy\n",
      "440 ../../feature/feature_logscale_stft/2017019880022_kimjaein/2017019880022_kimjaein_3.npy\n",
      "441 ../../feature/feature_logscale_stft/2017019880022_kimjaein/2017019880022_kimjaein_0.npy\n",
      "442 ../../feature/feature_logscale_stft/2017019880022_kimjaein/2017019880022_kimjaein_4.npy\n",
      "443 ../../feature/feature_logscale_stft/2017019880022_kimjaein/2017019880022_kimjaein_1.npy\n",
      "444 ../../feature/feature_logscale_stft/2017019880022_kimjaein/2017019880022_kimjaein_2.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445 ../../feature/feature_logscale_stft/2017019880023_yoohaekyung/2017019880023_yoohaekyung_0.npy\n",
      "446 ../../feature/feature_logscale_stft/2017019880023_yoohaekyung/2017019880023_yoohaekyung_4.npy\n",
      "447 ../../feature/feature_logscale_stft/2017019880023_yoohaekyung/2017019880023_yoohaekyung_2.npy\n",
      "448 ../../feature/feature_logscale_stft/2017019880023_yoohaekyung/2017019880023_yoohaekyung_1.npy\n",
      "449 ../../feature/feature_logscale_stft/2017019880023_yoohaekyung/2017019880023_yoohaekyung_3.npy\n",
      "450 ../../feature/feature_logscale_stft/2017019880024_hanyukyung/2017019880024_hanyukyung_2.npy\n",
      "451 ../../feature/feature_logscale_stft/2017019880024_hanyukyung/2017019880024_hanyukyung_0.npy\n",
      "452 ../../feature/feature_logscale_stft/2017019880024_hanyukyung/2017019880024_hanyukyung_4.npy\n",
      "453 ../../feature/feature_logscale_stft/2017019880024_hanyukyung/2017019880024_hanyukyung_1.npy\n",
      "454 ../../feature/feature_logscale_stft/2017019880024_hanyukyung/2017019880024_hanyukyung_3.npy\n",
      "455 ../../feature/feature_logscale_stft/2017019880025_yoojungkyun/2017019880025_yoojungkyun_3.npy\n",
      "456 ../../feature/feature_logscale_stft/2017019880025_yoojungkyun/2017019880025_yoojungkyun_2.npy\n",
      "457 ../../feature/feature_logscale_stft/2017019880025_yoojungkyun/2017019880025_yoojungkyun_0.npy\n",
      "458 ../../feature/feature_logscale_stft/2017019880025_yoojungkyun/2017019880025_yoojungkyun_1.npy\n",
      "459 ../../feature/feature_logscale_stft/2017019880025_yoojungkyun/2017019880025_yoojungkyun_4.npy\n",
      "460 ../../feature/feature_logscale_stft/2017019880026_parkjongsang/2017019880026_parkjongsang_1.npy\n",
      "461 ../../feature/feature_logscale_stft/2017019880026_parkjongsang/2017019880026_parkjongsang_0.npy\n",
      "462 ../../feature/feature_logscale_stft/2017019880026_parkjongsang/2017019880026_parkjongsang_2.npy\n",
      "463 ../../feature/feature_logscale_stft/2017019880026_parkjongsang/2017019880026_parkjongsang_4.npy\n",
      "464 ../../feature/feature_logscale_stft/2017019880026_parkjongsang/2017019880026_parkjongsang_3.npy\n",
      "465 ../../feature/feature_logscale_stft/2017019880027_leesol/2017019880027_leesol_3.npy\n",
      "466 ../../feature/feature_logscale_stft/2017019880027_leesol/2017019880027_leesol_2.npy\n",
      "467 ../../feature/feature_logscale_stft/2017019880027_leesol/2017019880027_leesol_0.npy\n",
      "468 ../../feature/feature_logscale_stft/2017019880027_leesol/2017019880027_leesol_1.npy\n",
      "469 ../../feature/feature_logscale_stft/2017019880027_leesol/2017019880027_leesol_4.npy\n",
      "470 ../../feature/feature_logscale_stft/2017019880028_kimsunghan/2017019880028_kimsunghan_3.npy\n",
      "471 ../../feature/feature_logscale_stft/2017019880028_kimsunghan/2017019880028_kimsunghan_0.npy\n",
      "472 ../../feature/feature_logscale_stft/2017019880028_kimsunghan/2017019880028_kimsunghan_2.npy\n",
      "473 ../../feature/feature_logscale_stft/2017019880028_kimsunghan/2017019880028_kimsunghan_1.npy\n",
      "474 ../../feature/feature_logscale_stft/2017019880028_kimsunghan/2017019880028_kimsunghan_4.npy\n",
      "475 ../../feature/feature_logscale_stft/2017019880029_kimminji/2017019880029_kimminji_4.npy\n",
      "476 ../../feature/feature_logscale_stft/2017019880029_kimminji/2017019880029_kimminji_1.npy\n",
      "477 ../../feature/feature_logscale_stft/2017019880029_kimminji/2017019880029_kimminji_3.npy\n",
      "478 ../../feature/feature_logscale_stft/2017019880029_kimminji/2017019880029_kimminji_0.npy\n",
      "479 ../../feature/feature_logscale_stft/2017019880029_kimminji/2017019880029_kimminji_2.npy\n",
      "480 ../../feature/feature_logscale_stft/2017019880030_hanseungoh/2017019880030_hanseungoh_2.npy\n",
      "481 ../../feature/feature_logscale_stft/2017019880030_hanseungoh/2017019880030_hanseungoh_1.npy\n",
      "482 ../../feature/feature_logscale_stft/2017019880030_hanseungoh/2017019880030_hanseungoh_3.npy\n",
      "483 ../../feature/feature_logscale_stft/2017019880030_hanseungoh/2017019880030_hanseungoh_4.npy\n",
      "484 ../../feature/feature_logscale_stft/2017019880030_hanseungoh/2017019880030_hanseungoh_0.npy\n",
      "485 ../../feature/feature_logscale_stft/2017019880031_ahnjiwoo/2017019880031_ahnjiwoo_4.npy\n",
      "486 ../../feature/feature_logscale_stft/2017019880031_ahnjiwoo/2017019880031_ahnjiwoo_2.npy\n",
      "487 ../../feature/feature_logscale_stft/2017019880031_ahnjiwoo/2017019880031_ahnjiwoo_1.npy\n",
      "488 ../../feature/feature_logscale_stft/2017019880031_ahnjiwoo/2017019880031_ahnjiwoo_3.npy\n",
      "489 ../../feature/feature_logscale_stft/2017019880031_ahnjiwoo/2017019880031_ahnjiwoo_0.npy\n"
     ]
    }
   ],
   "source": [
    "X_TF = []\n",
    "y_TF = []\n",
    "for i,fname in zip(range(0,len(fname_list)), fname_list):\n",
    "    print(i,fname)\n",
    "    \n",
    "    logscale_stft = image.load_img(npy_2_png(fname.split('/')[4],fname.split('/')[5]), target_size=(224,224))\n",
    "    tempX = image.img_to_array(logscale_stft)\n",
    "    tempX = np.expand_dims(tempX, axis=0)\n",
    "    tempX = preprocess_input(tempX)\n",
    "    \n",
    "    flatten = model.predict(tempX)\n",
    "    \n",
    "    X_TF.append(list(flatten[0]))\n",
    "    y_TF.append(class_names.index(fname.split('/')[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_TF_train = np.array(X_TF)\n",
    "y_TF_train = np.array(y_TF)\n",
    "\n",
    "X_TF_train, X_TF_test, y_TF_train, y_TF_test = train_test_split(X_TF_train, y_TF_train, test_size=0.30, random_state=42, stratify=y_TF_train)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_TF_train_encoded = tf.keras.utils.to_categorical(y_TF_train)\n",
    "y_TF_test_encoded = tf.keras.utils.to_categorical(y_TF_test)\n",
    "\n",
    "X_TF_train_reshape = X_TF_train.reshape(-1, X_TF_train.shape[1], 1)\n",
    "X_TF_test_reshape   = X_TF_test.reshape(-1, X_TF_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343, 2048, 1)\n",
      "(147, 2048, 1)\n",
      "(343, 98)\n",
      "(147, 98)\n"
     ]
    }
   ],
   "source": [
    "print(X_TF_train_reshape.shape)\n",
    "print(X_TF_test_reshape.shape)\n",
    "\n",
    "print(y_TF_train_encoded.shape)\n",
    "print(y_TF_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Learninig "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_npy_2_png (cname,fname):\n",
    "    if not os.path.exists(\"../../feature/feature_logscale_stft_validation_png/\"):\n",
    "        os.makedirs(\"../../feature/feature_logscale_stft_validation_png/\")\n",
    "    if not os.path.exists(\"../../feature/feature_logscale_stft_validation_png/\"+cname) :\n",
    "        os.makedirs(\"../../feature/feature_logscale_stft_validation_png/\"+cname)\n",
    "    \n",
    "    array = np.load(\"../../feature/feature_logscale_stft_validation/\"+cname+\"/\"+fname)\n",
    "    array = array - np.min(array)\n",
    "    array = array / np.max(array)\n",
    "    array = array * 255.0\n",
    "    \n",
    "    i = fname.split('_')[2].split('.')[0]\n",
    "    if os.path.exists(\"../../feature/feature_logscale_stft_validation_png/\"+cname+\"/{}.png\".format(i)):\n",
    "        os.remove(\"../../feature/feature_logscale_stft_validation_png/\"+cname+\"/{}.png\".format(i))\n",
    "        \n",
    "    imageio.imwrite(\"../../feature/feature_logscale_stft_validation_png/\"+cname+\"/{}.png\".format(i),array)\n",
    "    return \"../../feature/feature_logscale_stft_validation_png/\"+cname+\"/{}.png\".format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2048)\n",
      "0.9251700680272109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(X_TF_train, y_TF_train)\n",
    "\n",
    "predicted = clf.predict(X_TF_test)\n",
    "print(X_TF_test.shape)\n",
    "\n",
    "# get the accuracy\n",
    "print (accuracy_score(y_TF_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    kwakjuheon       1.00      1.00      1.00         1\n",
      "       kimjiho       1.00      1.00      1.00         2\n",
      "     songyejin       1.00      1.00      1.00         2\n",
      "     parksohui       1.00      1.00      1.00         2\n",
      "   moonyeonwoo       1.00      1.00      1.00         1\n",
      "     kangsubin       1.00      1.00      1.00         1\n",
      "  leekyeongeun       1.00      0.50      0.67         2\n",
      "   chochaeyeon       1.00      1.00      1.00         1\n",
      "  shindonghwan       1.00      1.00      1.00         2\n",
      "     kwakmirae       1.00      1.00      1.00         1\n",
      "  kimhyeryeong       1.00      1.00      1.00         1\n",
      "   chaeminjoon       0.50      1.00      0.67         1\n",
      "    kwakyiheon       1.00      1.00      1.00         1\n",
      "      leesumin       1.00      1.00      1.00         1\n",
      "   choihayoung       1.00      1.00      1.00         2\n",
      "     kangyeseo       1.00      1.00      1.00         1\n",
      "   kwakmihyang       1.00      1.00      1.00         1\n",
      "       eundano       1.00      1.00      1.00         2\n",
      "      limjinju       1.00      1.00      1.00         1\n",
      "    kimseongje       1.00      1.00      1.00         1\n",
      "  kwakbokyeong       1.00      1.00      1.00         2\n",
      "     ahnhyojin       1.00      1.00      1.00         2\n",
      "      heosehun       1.00      1.00      1.00         1\n",
      "     choijiwon       1.00      1.00      1.00         2\n",
      "   ahnjeongsuk       1.00      1.00      1.00         2\n",
      " parkyeongseon       1.00      1.00      1.00         1\n",
      "   kwaksangpil       0.00      0.00      0.00         1\n",
      "     kodohyeon       1.00      1.00      1.00         1\n",
      "      kwonyuna       1.00      1.00      1.00         1\n",
      "  kwoneunkyung       1.00      1.00      1.00         2\n",
      "       johaesu       1.00      1.00      1.00         1\n",
      "  leebyeongjin       1.00      1.00      1.00         1\n",
      "hyeonsanghyeok       1.00      1.00      1.00         2\n",
      "        jennie       1.00      1.00      1.00         1\n",
      "   simseungmin       1.00      1.00      1.00         1\n",
      "      parksomi       1.00      1.00      1.00         1\n",
      "       yuminji       0.00      0.00      0.00         2\n",
      "     parksojin       1.00      1.00      1.00         2\n",
      "   kwonyeonwoo       1.00      1.00      1.00         2\n",
      "    ladakyeong       1.00      1.00      1.00         1\n",
      "    janghyomin       1.00      1.00      1.00         1\n",
      "     parkeunbi       1.00      1.00      1.00         2\n",
      "   parkdayeung       1.00      1.00      1.00         1\n",
      "    parkjongae       1.00      1.00      1.00         2\n",
      "      hansohee       1.00      1.00      1.00         1\n",
      "    janggyeoul       1.00      1.00      1.00         1\n",
      "      leewooju       1.00      1.00      1.00         2\n",
      "     nomyungok       1.00      1.00      1.00         1\n",
      "   heoyoonjung       1.00      1.00      1.00         2\n",
      "     heojaemin       0.00      0.00      0.00         1\n",
      "     kimsoyung       1.00      1.00      1.00         2\n",
      "      chuminha       1.00      1.00      1.00         2\n",
      "    kimhyeonsu       1.00      1.00      1.00         2\n",
      "   chaesonghwa       1.00      1.00      1.00         1\n",
      "     kwonyulim       0.50      0.50      0.50         2\n",
      "   kimminyoung       1.00      1.00      1.00         1\n",
      "     jueunhong       1.00      1.00      1.00         2\n",
      "    leejeongju       1.00      1.00      1.00         2\n",
      "     kwonnahui       1.00      1.00      1.00         2\n",
      "    kimdayeong       1.00      1.00      1.00         2\n",
      "     kwonsundo       0.67      1.00      0.80         2\n",
      "     kimhyeona       1.00      1.00      1.00         2\n",
      "     leehyojin       1.00      1.00      1.00         1\n",
      "       yuminji       0.00      0.00      0.00         2\n",
      "    jeonghojun       1.00      1.00      1.00         1\n",
      "    kanghyeyun       1.00      1.00      1.00         1\n",
      "       ohjiwon       1.00      1.00      1.00         2\n",
      "      kimsubin       1.00      1.00      1.00         2\n",
      "    kimkihyeon       1.00      1.00      1.00         1\n",
      "      kimminji       0.00      0.00      0.00         1\n",
      "  myeongjaewon       1.00      1.00      1.00         1\n",
      "    kimjihyeon       1.00      1.00      1.00         2\n",
      "    choisuyeon       0.50      1.00      0.67         1\n",
      "   hwanghyebin       1.00      1.00      1.00         1\n",
      "    jangsoojin       1.00      1.00      1.00         2\n",
      "    kimhongjoo       1.00      1.00      1.00         1\n",
      "     kimhyorin       0.67      1.00      0.80         2\n",
      "     kimjihyun       1.00      1.00      1.00         2\n",
      "     kimsongyi       1.00      1.00      1.00         2\n",
      "      kotaewan       1.00      1.00      1.00         1\n",
      "     leedanbee       1.00      1.00      1.00         1\n",
      "   leejungjoon       1.00      1.00      1.00         1\n",
      "  parkjongkook       1.00      1.00      1.00         2\n",
      "   sungsoohyun       1.00      1.00      1.00         1\n",
      "     wonjoonho       1.00      1.00      1.00         2\n",
      "    wonsonghee       1.00      1.00      1.00         2\n",
      "    yoonhyeeun       1.00      1.00      1.00         2\n",
      "    kimjuyeong       1.00      1.00      1.00         2\n",
      "      kimjaein       0.00      0.00      0.00         1\n",
      "   yoohaekyung       1.00      0.50      0.67         2\n",
      "    hanyukyung       1.00      1.00      1.00         1\n",
      "   yoojungkyun       1.00      1.00      1.00         2\n",
      "  parkjongsang       1.00      1.00      1.00         2\n",
      "        leesol       1.00      1.00      1.00         1\n",
      "    kimsunghan       1.00      1.00      1.00         1\n",
      "      kimminji       1.00      1.00      1.00         2\n",
      "    hanseungoh       1.00      1.00      1.00         2\n",
      "      ahnjiwoo       1.00      1.00      1.00         2\n",
      "\n",
      "      accuracy                           0.93       147\n",
      "     macro avg       0.92      0.92      0.92       147\n",
      "  weighted avg       0.92      0.93      0.92       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [class_name.split('_')[1] for class_name in class_names]\n",
    "print(classification_report(y_TF_test, predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_TF_score = clf.fit(X_TF_train, y_TF_train).decision_function(X_TF_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(class_names)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_TF_test_encoded[:, i], y_TF_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_TF_test_encoded.ravel(), y_TF_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-8408cfd34546>:10: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(0, len(class_names))]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(0, len(class_names)):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= len(class_names)\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize = (14,10))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "lw =2\n",
    "for i, color in zip(range(len(class_names)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for ResNet50-SVM Model')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../../feature/feature_logscale_stft_validation/2017019740001_kwakjuheon/2017019740001_kwakjuheon_4.npy\n",
      "1 ../../feature/feature_logscale_stft_validation/2017019740001_kwakjuheon/2017019740001_kwakjuheon_1.npy\n",
      "2 ../../feature/feature_logscale_stft_validation/2017019740001_kwakjuheon/2017019740001_kwakjuheon_0.npy\n",
      "3 ../../feature/feature_logscale_stft_validation/2017019740001_kwakjuheon/2017019740001_kwakjuheon_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ../../feature/feature_logscale_stft_validation/2017019740001_kwakjuheon/2017019740001_kwakjuheon_3.npy\n",
      "5 ../../feature/feature_logscale_stft_validation/2017019880001_kimsubin/2017019880001_kimsubin_1.npy\n",
      "6 ../../feature/feature_logscale_stft_validation/2017019880001_kimsubin/2017019880001_kimsubin_4.npy\n",
      "7 ../../feature/feature_logscale_stft_validation/2017019880001_kimsubin/2017019880001_kimsubin_3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ../../feature/feature_logscale_stft_validation/2017019880001_kimsubin/2017019880001_kimsubin_0.npy\n",
      "9 ../../feature/feature_logscale_stft_validation/2017019880001_kimsubin/2017019880001_kimsubin_2.npy\n",
      "Predict : 2017019740001_kwakjuheon , Real : 2017019740001_kwakjuheon\n",
      "Predict : 2017019740001_kwakjuheon , Real : 2017019740001_kwakjuheon\n",
      "Predict : 2017019880016_parkjongkook , Real : 2017019740001_kwakjuheon\n",
      "Predict : 2017019880016_parkjongkook , Real : 2017019740001_kwakjuheon\n",
      "Predict : 2017019740001_kwakjuheon , Real : 2017019740001_kwakjuheon\n",
      "Predict : 2017019740026_parkyeongseon , Real : 2017019880001_kimsubin\n",
      "Predict : 2017019740026_parkyeongseon , Real : 2017019880001_kimsubin\n",
      "Predict : 2017019770031_kwonnahui , Real : 2017019880001_kimsubin\n",
      "Predict : 2017019770008_parksomi , Real : 2017019880001_kimsubin\n",
      "Predict : 2017019880001_kimsubin , Real : 2017019880001_kimsubin\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(X_TF_train, y_TF_train)\n",
    "\n",
    "x_validation_list=[]\n",
    "y_validation_list=[]\n",
    "\n",
    "val_class_names = os.listdir(\"../../feature/feature_logscale_stft_validation/\")\n",
    "val_class_names.sort()\n",
    "val_fname=[]\n",
    "\n",
    "for i in range(0,len(val_class_names)):\n",
    "    val_files=os.listdir(\"../../feature/feature_logscale_stft_validation/\"+val_class_names[i])\n",
    "    val_files = [file for file in val_files if file.endswith(\".npy\")]\n",
    "    for j in range(0, len(val_files)):\n",
    "        val_fname.append(\"../../feature/feature_logscale_stft_validation/\"+val_class_names[i]+\"/\"+val_files[j])\n",
    "\n",
    "X_TF_pred = []\n",
    "y_TF_pred = []\n",
    "\n",
    "for i,fname in zip(range(0,len(val_fname)), val_fname):\n",
    "    print(i,fname)\n",
    "    \n",
    "    logscale_stft = image.load_img(val_npy_2_png(fname.split('/')[4],fname.split('/')[5]), target_size=(224,224))\n",
    "    tempX = image.img_to_array(logscale_stft)\n",
    "    tempX = np.expand_dims(tempX, axis=0)\n",
    "    tempX = preprocess_input(tempX)\n",
    "    \n",
    "    flatten = model.predict(tempX)\n",
    "    \n",
    "    X_TF_pred.append(list(flatten[0]))\n",
    "    y_TF_pred.append(val_class_names.index(fname.split('/')[4]))\n",
    "\n",
    "    \n",
    "X_TF_pred = np.array(X_TF_pred)\n",
    "y_TF_pred = np.array(y_TF_pred)\n",
    "y_TF_pred_encode = tf.keras.utils.to_categorical(y_TF_pred)\n",
    "\n",
    "predicted = clf.predict(X_TF_pred)\n",
    "real =[]\n",
    "for i,pred in zip(range(0, len(predicted)), predicted) :\n",
    "    print(\"Predict :\",class_names[pred], \", Real :\", val_class_names[y_TF_pred[i]])\n",
    "    real.append(class_names.index(val_class_names[y_TF_pred[i]]))\n",
    "# \n",
    "# get the accuracy\n",
    "print (accuracy_score(real, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_TF_train, y_TF_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 2048)\n",
      "0.2839506172839506\n"
     ]
    }
   ],
   "source": [
    "predicted_gb = gbrt.predict(X_TF_test)\n",
    "print(X_TF_test.shape)\n",
    "\n",
    "# get the accuracy\n",
    "print (accuracy_score(y_TF_test, predicted_gb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
