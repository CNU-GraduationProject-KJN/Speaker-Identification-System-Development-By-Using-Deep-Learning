{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vivek081166/raw-audio-deep-learning/blob/master/constants.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from shutil import rmtree\n",
    "from constants import *\n",
    "# from constants import DATA_AUDIO_DIR\n",
    "\n",
    "DATA_AUDIO_DIR = './test_train_data'\n",
    "list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "list_dir.sort()\n",
    "TARGET_SR = 8000\n",
    "AUDIO_LENGTH = 100000\n",
    "\n",
    "def mkdir_p(path):\n",
    "    import errno\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "# def del_folder(path):\n",
    "#     try:\n",
    "#         rmtree(path)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "\n",
    "# del_folder(OUTPUT_DIR_TRAIN)\n",
    "# del_folder(OUTPUT_DIR_TEST)\n",
    "# mkdir_p(OUTPUT_DIR_TRAIN)\n",
    "# mkdir_p(OUTPUT_DIR_TEST)\n",
    "\n",
    "order = 0\n",
    "class_ids = {list_dir[i]: i for i in range(len(list_dir))}\n",
    "\n",
    "\n",
    "def extract_class_id(wav_filename):\n",
    "    return class_ids.get(wav_filename[18:-6])\n",
    "\n",
    "\n",
    "def read_audio_from_filename(filename, target_sr):\n",
    "    audio, _ = librosa.load(filename, sr=target_sr, mono=True)\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def convert_data():\n",
    "    DATA_AUDIO_DIR = './test_train_data'\n",
    "    list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "    list_dir.sort()\n",
    "#     TARGET_SR = 16000\n",
    "#     AUDIO_LENGTH = 200000\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(DATA_AUDIO_DIR, '**/**.wav'), recursive=True)):\n",
    "#         print(i, wav_filename)\n",
    "        class_id = extract_class_id(wav_filename)\n",
    "        audio_buf = read_audio_from_filename(wav_filename, target_sr=TARGET_SR)\n",
    "        # normalize mean 0, variance 1\n",
    "        audio_buf = (audio_buf - np.mean(audio_buf)) / np.std(audio_buf)\n",
    "        original_length = len(audio_buf)\n",
    "        print(i, wav_filename, original_length, np.round(np.mean(audio_buf), 4), np.std(audio_buf))\n",
    "        if original_length < AUDIO_LENGTH:\n",
    "            audio_buf = np.concatenate((audio_buf, np.zeros(shape=(AUDIO_LENGTH - original_length, 1))))\n",
    "            print('PAD New length =', len(audio_buf))\n",
    "        elif original_length > AUDIO_LENGTH:\n",
    "            audio_buf = audio_buf[20000:AUDIO_LENGTH+20000]\n",
    "            print('CUT New length =', len(audio_buf))\n",
    "\n",
    "        output_folder = OUTPUT_DIR_TRAIN\n",
    "        if wav_filename[-5:] == '5.wav':\n",
    "            output_folder = OUTPUT_DIR_TEST\n",
    "\n",
    "        output_filename = os.path.join(output_folder, str(wav_filename[18:-4]).replace('/', '_') + '.pkl')\n",
    "#         TARGET_SR = 16000\n",
    "        out = {'class_id': class_id,\n",
    "               'audio': audio_buf,\n",
    "               'sr': TARGET_SR}\n",
    "        print(\"-----------------\")\n",
    "        print(out)\n",
    "        with open(output_filename, 'wb') as w:\n",
    "            pickle.dump(out, w)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "!!!!!!!! 125\n",
      "Using Model M5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 25000, 128)        10368     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 25000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 25000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 6250, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 6250, 128)         49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6250, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6250, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1562, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1562, 256)         98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1562, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1562, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 390, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 390, 512)          393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 390, 512)          2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 390, 512)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 97, 512)           0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 125)               64125     \n",
      "=================================================================\n",
      "Total params: 620,157\n",
      "Trainable params: 618,109\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n",
      "x_tr.shape = (954, 100000, 1)\n",
      "y_tr.shape = (954, 125)\n",
      "x_te.shape = (238, 100000, 1)\n",
      "y_te.shape = (238, 125)\n",
      "<class 'numpy.ndarray'>\n",
      "Train on 954 samples, validate on 238 samples\n",
      "Epoch 1/100\n",
      "954/954 - 10s - loss: 4.2086 - accuracy: 0.1593 - val_loss: 4.4720 - val_accuracy: 0.0588\n",
      "Epoch 2/100\n",
      "954/954 - 6s - loss: 2.2907 - accuracy: 0.4769 - val_loss: 3.6723 - val_accuracy: 0.2731\n",
      "Epoch 3/100\n",
      "954/954 - 6s - loss: 1.4871 - accuracy: 0.6813 - val_loss: 2.6946 - val_accuracy: 0.3992\n",
      "Epoch 4/100\n",
      "954/954 - 6s - loss: 1.0428 - accuracy: 0.8040 - val_loss: 1.6066 - val_accuracy: 0.6975\n",
      "Epoch 5/100\n",
      "954/954 - 6s - loss: 0.7412 - accuracy: 0.8742 - val_loss: 1.5450 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "954/954 - 6s - loss: 0.6084 - accuracy: 0.8962 - val_loss: 0.9578 - val_accuracy: 0.7941\n",
      "Epoch 7/100\n",
      "954/954 - 6s - loss: 0.4477 - accuracy: 0.9371 - val_loss: 0.6830 - val_accuracy: 0.8655\n",
      "Epoch 8/100\n",
      "954/954 - 6s - loss: 0.3641 - accuracy: 0.9570 - val_loss: 0.7064 - val_accuracy: 0.8361\n",
      "Epoch 9/100\n",
      "954/954 - 6s - loss: 0.3225 - accuracy: 0.9539 - val_loss: 0.5984 - val_accuracy: 0.8655\n",
      "Epoch 10/100\n",
      "954/954 - 6s - loss: 0.3073 - accuracy: 0.9623 - val_loss: 0.4825 - val_accuracy: 0.9076\n",
      "Epoch 11/100\n",
      "954/954 - 6s - loss: 0.2529 - accuracy: 0.9696 - val_loss: 0.3612 - val_accuracy: 0.9454\n",
      "Epoch 12/100\n",
      "954/954 - 6s - loss: 0.2258 - accuracy: 0.9633 - val_loss: 0.4231 - val_accuracy: 0.9328\n",
      "Epoch 13/100\n",
      "954/954 - 6s - loss: 0.2376 - accuracy: 0.9665 - val_loss: 0.4921 - val_accuracy: 0.8908\n",
      "Epoch 14/100\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import convert_to_tensor\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "AUDIO_LENGTH = 100000\n",
    "OUTPUT_DIR = './output_ver1'\n",
    "OUTPUT_DIR_TRAIN = os.path.join(OUTPUT_DIR, 'train')\n",
    "OUTPUT_DIR_TEST = os.path.join(OUTPUT_DIR, 'test')\n",
    "\n",
    "DATA_AUDIO_DIR = '../test_train_data'\n",
    "list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "list_dir.sort()\n",
    "# TARGET_SR = 16000\n",
    "\n",
    "class_ids = {list_dir[i]: i for i in range(len(list_dir))}\n",
    "def m5(num_classes):\n",
    "    print(\"!!!!!!!!\", num_classes)\n",
    "    print('Using Model M5')\n",
    "    m = Sequential()\n",
    "    m.add(Conv1D(128,\n",
    "                 input_shape=[AUDIO_LENGTH, 1],\n",
    "                 kernel_size=80,\n",
    "                 strides=4,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Conv1D(128,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Conv1D(256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Conv1D(512,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
    "    m.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
    "    m.add(Dense(num_classes, activation='softmax'))\n",
    "    return m\n",
    "\n",
    "\n",
    "def get_data(file_list):\n",
    "    def load_into(_filename, _x, _y):\n",
    "        with open(_filename, 'rb') as f:\n",
    "            audio_element = pickle.load(f)\n",
    "            _x.append(audio_element['audio'])\n",
    "            _y.append(int(audio_element['class_id']))\n",
    "\n",
    "    x, y = [], []\n",
    "    for filename in file_list:\n",
    "#         print(\"Predict file name : \", filename)\n",
    "        load_into(filename, x, y)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = len(list_dir)\n",
    "print(num_classes)\n",
    "model = m5(num_classes=len(list_dir))\n",
    "\n",
    "if model is None:\n",
    "    exit('Something went wrong!!')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "train_files = glob(os.path.join(OUTPUT_DIR_TRAIN, '**.pkl'))\n",
    "x_tr, y_tr = get_data(train_files)\n",
    "y_tr = to_categorical(y_tr, num_classes=num_classes)\n",
    "\n",
    "test_files = glob(os.path.join(OUTPUT_DIR_TEST, '**.pkl'))\n",
    "x_te, y_te = get_data(test_files)\n",
    "y_te = to_categorical(y_te, num_classes=num_classes)\n",
    "\n",
    "print('x_tr.shape =', x_tr.shape)\n",
    "print('y_tr.shape =', y_tr.shape)\n",
    "print('x_te.shape =', x_te.shape)\n",
    "print('y_te.shape =', y_te.shape)\n",
    "print(type(x_te))\n",
    "\n",
    "# if the accuracy does not increase over 10 epochs, reduce the learning rate by half.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
    "batch_size = 128\n",
    "history = model.fit(x=x_tr, y=y_tr, batch_size=16, epochs=100, verbose=2, shuffle=True, validation_data=(x_te, y_te), callbacks=[reduce_lr])\n",
    "    \n",
    "# epoch 500 audio_length 10000 min_lr 0.0001 sr 8000 batch_size 16 : val_acc 0.73\n",
    "# epoch 500 audio_length 10000 min_lr 0.00005 sr 8000 batch_size 16 : val_acc 0.77(0.83)\n",
    "# epoch 50 audio_length 20000 min_lr 0.00005 sr 8000 batch_size 16 : val_acc 0.90\n",
    "# epoch 100 audio_length 20000 min_lr 0.00005 sr 8000 batch_size 16 : val_acc 0.93\n",
    "# epoch 100 audio_length 20000 min_lr 0.00005 sr 8000 batch_size 32 : val_acc 0.89(0.90) predict 0.75\n",
    "# epoch 150 audio_length 20000 min_lr 0.00005 sr 8000 batch_size 16 : val_acc 0.91 predict 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.rc('font', size=18)\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train_accuracy\", \"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pickle\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from shutil import rmtree\n",
    "from constants import *\n",
    "from constants import DATA_AUDIO_DIR\n",
    "DATA_AUDIO_VAL_DIR = '../test_val_data'\n",
    "OUTPUT_DIR_VAL_TRAIN = './output_val/train'\n",
    "OUTPUT_DIR_VAL_TEST = './output_val/test'\n",
    "\n",
    "\n",
    "DATA_AUDIO_DIR = '../test_train_data'\n",
    "list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "list_dir.sort()\n",
    "\n",
    "class_ids = {list_dir[i]: i for i in range(len(list_dir))}\n",
    "\n",
    "\n",
    "def extract_class_id(wav_filename):\n",
    "    return class_ids.get(wav_filename[18:-6])\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    import errno\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "# def del_folder(path):\n",
    "#     try:\n",
    "#         rmtree(path)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "\n",
    "# del_folder(OUTPUT_DIR_TRAIN)\n",
    "# del_folder(OUTPUT_DIR_TEST)\n",
    "# mkdir_p(OUTPUT_DIR_TRAIN)\n",
    "# mkdir_p(OUTPUT_DIR_TEST)\n",
    "\n",
    "class_ids = {list_dir[i]: i for i in range(len(list_dir))}\n",
    "\n",
    "\n",
    "def extract_class_id(wav_filename):\n",
    "    return class_ids.get(wav_filename[16:-6].replace('/', ''))\n",
    "\n",
    "\n",
    "def read_audio_from_filename(filename, target_sr):\n",
    "    audio, _ = librosa.load(filename, sr=target_sr, mono=True)\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def convert_data():\n",
    "    DATA_AUDIO_DIR = '../test_train_data'\n",
    "    list_dir = os.listdir(DATA_AUDIO_VAL_DIR)\n",
    "    list_dir.sort()\n",
    "    print(list_dir)\n",
    "    AUDIO_LENGTH = 100000\n",
    "    TARGET_SR = 8000\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(DATA_AUDIO_VAL_DIR, '**/**.wav'), recursive=True)):\n",
    "        print(i, wav_filename)\n",
    "        class_id = extract_class_id(wav_filename)\n",
    "        audio_buf = read_audio_from_filename(wav_filename, target_sr=TARGET_SR)\n",
    "        # normalize mean 0, variance 1\n",
    "        audio_buf = (audio_buf - np.mean(audio_buf)) / np.std(audio_buf)\n",
    "        original_length = len(audio_buf)\n",
    "        print(i, wav_filename, original_length, np.round(np.mean(audio_buf), 4), np.std(audio_buf))\n",
    "        if original_length < AUDIO_LENGTH:\n",
    "            audio_buf = np.concatenate((audio_buf, np.zeros(shape=(AUDIO_LENGTH - original_length, 1))))\n",
    "            print('PAD New length =', len(audio_buf))\n",
    "        elif original_length > AUDIO_LENGTH:\n",
    "            audio_buf = audio_buf[20000:AUDIO_LENGTH+20000]\n",
    "#             audio_buf = audio_buf[10000:AUDIO_LENGTH+10000]\n",
    "            print('CUT New length =', len(audio_buf))\n",
    "\n",
    "        output_folder = OUTPUT_DIR_VAL_TRAIN\n",
    "#         if i % 5 == 0:\n",
    "#             output_folder = OUTPUT_DIR_VAL_TEST\n",
    "\n",
    "        output_filename = os.path.join(output_folder, str(wav_filename[16:-4]).replace('/', '_') + '.pkl')\n",
    "\n",
    "        out = {'class_id': class_id,\n",
    "               'audio': audio_buf,\n",
    "               'sr': TARGET_SR}\n",
    "        print(\"-----------------\")\n",
    "        print(out)\n",
    "        with open(output_filename, 'wb') as w:\n",
    "            pickle.dump(out, w)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DATA_AUDIO_VAL_DIR = '../test_val_data'\n",
    "OUTPUT_DIR_VAL_TRAIN = './output_val_ver1/train'\n",
    "OUTPUT_DIR_VAL_TEST = './output_val_ver1/test'\n",
    "\n",
    "train_files_1 = glob(os.path.join(OUTPUT_DIR_VAL_TRAIN, '**.pkl'))\n",
    "train_files_1.sort()\n",
    "\n",
    "x_tr_1, y_tr_1 = get_data(train_files_1)\n",
    "print('y_tr_1 : ', y_tr_1)\n",
    "\n",
    "y_tr_12 = to_categorical(y_tr_1, num_classes=num_classes)\n",
    "\n",
    "pred_out = model.predict(x_tr_1)\n",
    "\n",
    "real =[]\n",
    "pred_out_idex=[]\n",
    "\n",
    "val_class_names = os.listdir(DATA_AUDIO_VAL_DIR)\n",
    "print(val_class_names)\n",
    "# val_class_names.sort()\n",
    "\n",
    "DATA_AUDIO_DIR = '../test_train_data'\n",
    "list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "list_dir.sort()\n",
    "\n",
    "j = 0\n",
    "for i,pred in zip(range(0, len(pred_out)), pred_out) :\n",
    "    print(\"Predict :\",list_dir[np.argmax(pred)], \", Real :\", list_dir[y_tr_1[i]], \", 값: \",np.max(pred))\n",
    "    real.append(list_dir.index(list_dir[y_tr_1[i]]))\n",
    "    pred_out_idex.append(np.argmax(pred))\n",
    "    \n",
    "# get the accuracy\n",
    "print (accuracy_score(real, pred_out_idex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm # for color map\n",
    "from python_speech_features import logfbank, fbank\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "\n",
    "# Library for performing speech recognition\n",
    "# Python 2.6, 2.7, or 3.3+ (required)\n",
    "# PyAudio 0.2.11+ (required only if you need to use microphone input, Microphone)\n",
    "# More : https://github.com/Uberi/speech_recognition\n",
    "import speech_recognition as sr \n",
    "import scipy.signal as signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 데이터 녹음\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../test_pred_data/\"\n",
    "r = sr.Recognizer() \n",
    "\n",
    "print(\"음성 데이터 녹음\")\n",
    "file_name = str(input(\"이름을 입력하세요 : \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0 =sr.Microphone.list_microphone_names()\n",
    "for i in range(0, len(list_0)-1):\n",
    "    print(list_0[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher sample_rate result in better audio quality, slower recognition\n",
    "# Higher chunk_size help avoid triggering on rapidly changing ambient noise,\n",
    "#  but also makes detection less sensitive\n",
    "microphone = sr.Microphone(device_index=7, sample_rate=None, chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with microphone as source:\n",
    "    print(\"30초 동안 녹음을 시작합니다.\")\n",
    "    print(\"녹음이 시작되면 다음 문장을 읽어주세요.\\n\")\n",
    "        \n",
    "    print(\"총체주의는 특정 가설에 대해 제기되는 반박이 결정적인 것처럼 보이더라도 그 가설이 실용적으로 필요하다고 인정되면 언제든 그와 같은 반박을 피하는 방법을 강구하여 그 가설을 받아들잉 수 있다. 그러나 총체주의는 \\\"A이면서 동시에 A가 아닐수는 없다.\\\"와 같은 논리학의 법칙처럼 아무도 의심하지 않는 지식은 분석 명제로 분류해야 하는 것이 아니냐는 비판에 답해야 하는 어려움이 있다.\")\n",
    "        \n",
    "    sleep(4)\n",
    "        \n",
    "        \n",
    "    print(\"*****   녹음 시작   *****\\n\")\n",
    "        \n",
    "    # This method reads the first second of the file stream \n",
    "    # and calibrates the recognizer to the noise level of the audio.\n",
    "    # adjust_for_ambient_noise는 첫 번째 초에 해당하는 오디오를 듣고 노이즈를 교정하는 메소드\n",
    "    r.adjust_for_ambient_noise(, duration=1)\n",
    "        \n",
    "    '''\n",
    "    !! adjust_for_ambient_noise를 사용하면 첫 번째 초를 잃게 됨. -> sleep(4)인 이유\n",
    "    !! 오디오의 1초는 노이즈 레벨을 판단하는 요소 : duration 으로 조정 가능, 가능한 0.5초 이상인게 좋다.\n",
    "    !! durations longer than the default of one second generate better results.\n",
    "    !! durations의 최솟값은 마이크의 주변 환경에 따라 다름.\n",
    "    '''\n",
    "        \n",
    "    # This method takes an audio source as its first argument and\n",
    "    # records input from the source until silence is detected.\n",
    "    # microphone의 입력을 감지, 무음이 감지될 때까지 소스의 입력을 기록한다. -> 종료되는 오류의 원인일 가능성    \n",
    "    audio = r.listen(source , phrase_time_limit=30)\n",
    "        \n",
    "    # audio는 AudioData(frame_data, source.SAMPLE_RATE, source.SAMPLE_WIDTH)\n",
    "        \n",
    "        \n",
    "    print(\" 녹음 완료. \")\n",
    "        \n",
    "        \n",
    "    # Audio file 저장\n",
    "    save_path = \"../test_pred_data/\"\n",
    "        \n",
    "    if not os.path.exists(save_path + file_name):\n",
    "        os.makedirs(save_path + file_name)\n",
    "        result_name = file_name +\"_\"+str(0)\n",
    "    else :\n",
    "        files = os.listdir(save_path + file_name)\n",
    "        result_name = file_name +\"_\"+str(len(files))\n",
    "        \n",
    "    with open(save_path + file_name + \"/\" + result_name+\".wav\", \"wb\") as f:\n",
    "        f.write(audio.get_wav_data()) # AudioData to .wav\n",
    "        print(\"''\"+result_name + \"' File Write Finish !\")\n",
    "            \n",
    "    print(\" Saved File Name : \"+result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from shutil import rmtree\n",
    "from constants import *\n",
    "from constants import DATA_AUDIO_DIR\n",
    "\n",
    "DATA_AUDIO_VAL_DIR = save_path+file_name\n",
    "OUTPUT_DIR_VAL_TRAIN = './output_pred/train'\n",
    "list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "list_dir.sort()\n",
    "\n",
    "class_ids = {list_dir[i]: i for i in range(len(list_dir))}\n",
    "\n",
    "\n",
    "def extract_class_id(wav_filename):\n",
    "    return class_ids.get(wav_filename[18:-6])\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    import errno\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "# def del_folder(path):\n",
    "#     try:\n",
    "#         rmtree(path)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "\n",
    "# del_folder(OUTPUT_DIR_TRAIN)\n",
    "# del_folder(OUTPUT_DIR_TEST)\n",
    "# mkdir_p(OUTPUT_DIR_TRAIN)\n",
    "# mkdir_p(OUTPUT_DIR_TEST)\n",
    "\n",
    "class_ids = {list_dir[i]: i for i in range(len(list_dir))}\n",
    "\n",
    "\n",
    "def extract_class_id(wav_filename):\n",
    "    return class_ids.get(wav_filename[16:-6].replace('/', ''))\n",
    "\n",
    "\n",
    "def read_audio_from_filename(filename, target_sr):\n",
    "    audio, _ = librosa.load(filename, sr=target_sr, mono=True)\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def convert_data():\n",
    "    DATA_AUDIO_DIR = '../test_train_data'\n",
    "    list_dir = os.listdir(DATA_AUDIO_VAL_DIR)\n",
    "    list_dir.sort()\n",
    "    print(list_dir)\n",
    "    AUDIO_LENGTH = 100000\n",
    "    TARGET_SR = 8000\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(DATA_AUDIO_VAL_DIR, '**/**.wav'), recursive=True)):\n",
    "        print(i, wav_filename)\n",
    "        class_id = extract_class_id(wav_filename)\n",
    "        audio_buf = read_audio_from_filename(wav_filename, target_sr=TARGET_SR)\n",
    "        # normalize mean 0, variance 1\n",
    "        audio_buf = (audio_buf - np.mean(audio_buf)) / np.std(audio_buf)\n",
    "        original_length = len(audio_buf)\n",
    "        print(i, wav_filename, original_length, np.round(np.mean(audio_buf), 4), np.std(audio_buf))\n",
    "        if original_length < AUDIO_LENGTH:\n",
    "            audio_buf = np.concatenate((audio_buf, np.zeros(shape=(AUDIO_LENGTH - original_length, 1))))\n",
    "            print('PAD New length =', len(audio_buf))\n",
    "        elif original_length > AUDIO_LENGTH:\n",
    "            audio_buf = audio_buf[20000:AUDIO_LENGTH+20000]\n",
    "#             audio_buf = audio_buf[10000:AUDIO_LENGTH+10000]\n",
    "            print('CUT New length =', len(audio_buf))\n",
    "\n",
    "        output_folder = OUTPUT_DIR_VAL_TRAIN\n",
    "#         if i % 5 == 0:\n",
    "#             output_folder = OUTPUT_DIR_VAL_TEST\n",
    "\n",
    "        output_filename = os.path.join(output_folder, str(wav_filename[16:-4]).replace('/', '_') + '.pkl')\n",
    "\n",
    "        out = {'class_id': class_id,\n",
    "               'audio': audio_buf,\n",
    "               'sr': TARGET_SR}\n",
    "        print(\"-----------------\")\n",
    "        print(out)\n",
    "        with open(output_filename, 'wb') as w:\n",
    "            pickle.dump(out, w)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DATA_AUDIO_VAL_DIR = save_path+file_name\n",
    "OUTPUT_DIR_VAL_TRAIN = './output_pred/train'\n",
    "\n",
    "train_files_1 = glob(os.path.join(OUTPUT_DIR_VAL_TRAIN, '**.pkl'))\n",
    "train_files_1.sort()\n",
    "\n",
    "x_tr_1, y_tr_1 = get_data(train_files_1)\n",
    "print('y_tr_1 : ', y_tr_1)\n",
    "\n",
    "y_tr_12 = to_categorical(y_tr_1, num_classes=num_classes)\n",
    "\n",
    "pred_out = model.predict(x_tr_1)\n",
    "\n",
    "real =[]\n",
    "pred_out_idex=[]\n",
    "\n",
    "val_class_names = os.listdir(DATA_AUDIO_VAL_DIR)\n",
    "print(val_class_names)\n",
    "# val_class_names.sort()\n",
    "\n",
    "DATA_AUDIO_DIR = '../test_train_data'\n",
    "list_dir = os.listdir(DATA_AUDIO_DIR)\n",
    "list_dir.sort()\n",
    "\n",
    "j = 0\n",
    "for i,pred in zip(range(0, len(pred_out)), pred_out) :\n",
    "    print(\"Predict :\",list_dir[np.argmax(pred)], \", Real :\", list_dir[y_tr_1[i]], \", 값: \",np.max(pred))\n",
    "    real.append(list_dir.index(list_dir[y_tr_1[i]]))\n",
    "    pred_out_idex.append(np.argmax(pred))\n",
    "    \n",
    "# get the accuracy\n",
    "print (accuracy_score(real, pred_out_idex))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
